{
  
    
        "post0": {
            "title": "SPAIN-AI 2020 Hackathon Reto Series Temporales",
            "content": "If ifs and ands were pots and pans... . https://www.spain-ai.com/hackathon2020_reto_Series_Temporales.php . https://competitions.codalab.org/competitions/28630 . This blog post details the code I used in this competition. It is provided here as a support to the SPAIN-AI presentation scheduled for 15 May 2021. Both the presentation and this post are in Spanish, since SPAIN-AI serves a Spanish speaking audience. . Esta blog detalla el código que utilicé en este concurso. Se ofrece aquí como apoyo a la presentación de SPAIN-AI prevista para el 15 de mayo de 2021. Tanto la presentación como este blog están en español, ya que SPAIN-AI atiende a un público hispanoparlante. . Presentation from 15 Mayo 2021 . to be added . Imports . import os import pandas as pd import numpy as np import matplotlib.pyplot as plt from collections import Counter import warnings warnings.simplefilter(&quot;ignore&quot;, UserWarning) pd.set_option(&#39;display.max_rows&#39;, 100) . . Reto: Lo que tien&#237;a que hacer . Entender el reto . Crea una cartera de activos (darwins), maximizando el ratio de Sharpe: . escoje 18 darwins de los 96 que están en los datos de entrenamiento | asigna una parte de la inversión total a cada uno de los 18 darwins | ajusta la asignación a lo largo del tiempo, cada hora desde el 18 agosto 2020 hasta el 24 diciembre 2020, los 2229 horas que están en el fichero submission.csv | calcula el ratio de Sharpe | . No es un problema de predicción (todos los datos son disponible el darwinex.com) pero de creación de una cartera diversificada de activos no correlacionados entre sí, que tienen rendimientos estables. . La métrica a maximizar . $$S = frac{E[R_a-R_b]}{ sigma_a}$$ . $R_a$ es el rendimiento de la cartera . $R_b$ es el rendimiento de una inversión de referencia . $ sigma_a$ es la desviación estándar (volatilidad) del exceso de rendimiento de la inversión . Asumiendo que $R_b$ fuera constante, hay que maximizar el rendimiento dividido por la volatilidad, así que buscamos rendimientos estables. . Necesita % inversión por cada hora . xs = [2,6,10,14,18,22,25,35,40,43,45,50,54,57,59,66,70,77] ys = np.array([0.0173,0.0379,0.0629,0.0309,0.1232,0.0654,0.2552,0.0076,0.0378,0.0235,0.0329,0.0487,0.0272,0.0383,0.0762,0.0165,0.0930,0.0055])*100 fig = plt.figure(figsize=(20,8)) ax = fig.add_subplot() ax.scatter(xs,ys, color=&#39;#ffe559&#39;) ax.set_xlabel(&#39;Darwin&#39;) ax.set_ylabel(&#39;% inversión&#39;) annotations=[&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;FIR&#39;, &#39;HEO&#39;, &#39;JTL&#39;, &#39;MUF&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;TXR&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] for i, label in enumerate(annotations): plt.annotate(label, (xs[i], ys[i])) plt.xticks([]) plt.tight_layout() plt.savefig(&quot;darwins.png&quot;) plt.show() . . Realidad: Lo que hice . Explora los datos hist&#243;ricos de entrenamiento - calcula score . candles=pd.DataFrame(columns=[&#39;date&#39;,&#39;close&#39;,&#39;max&#39;,&#39;min&#39;,&#39;open&#39;,&#39;std_dev&#39;,&#39;score&#39;,&#39;darwin&#39;]) filenames = [x for x in os.listdir(&#39;./data/TrainCandles&#39;)] for filename in filenames: df=pd.read_csv(&#39;./data/TrainCandles/&#39;+filename).rename(columns={&#39;Unnamed: 0&#39;:&#39;date&#39;}) df.date = pd.to_datetime(df.date) df[&#39;std_dev&#39;]=df.std(axis=1) df[&#39;score&#39;]=(round((df.close-df.open)/df.std_dev,6)).fillna(0) df[&#39;darwin&#39;]=filename[-13:-10] candles=candles.append(df) candles.head() . date close max min open std_dev score darwin . 0 2019-08-04 21:00:00 | 110.40 | 110.46 | 110.37 | 110.38 | 0.040311 | 0.496139 | HCC | . 1 2019-08-04 22:00:00 | 110.57 | 110.63 | 110.32 | 110.41 | 0.142683 | 1.121370 | HCC | . 2 2019-08-04 23:00:00 | 110.49 | 110.57 | 110.45 | 110.57 | 0.060000 | -1.333333 | HCC | . 3 2019-08-05 00:00:00 | 110.51 | 110.60 | 110.38 | 110.48 | 0.090692 | 0.330791 | HCC | . 4 2019-08-05 01:00:00 | 109.94 | 110.68 | 109.90 | 110.50 | 0.394081 | -1.421027 | HCC | . plt.hist(candles.score, color=&#39;#FFE599&#39;) plt.title(&#39;Count of hourly scores&#39;); . Identifica qué darwin tenía el máximo score en cada hora. . Conta cuánto veces cada darwin tiene el máximo score. . Investiga esos darwins primero. . lst=[candles[(candles[&#39;date&#39;]==hour) &amp; (candles.score==candles[candles[&#39;date&#39;]==hour].score.max())].darwin.to_list()[0] for hour in sorted(candles[&#39;date&#39;].unique())] count_dict=Counter(lst) df=pd.DataFrame.from_dict(count_dict, orient=&#39;index&#39;).sort_values(0, ascending=False) darwins_lst=df.index.to_list() darwins_lst=darwins_lst+[&#39;MMY&#39;,&#39;TMF&#39;] # the 2 darwins that never had max score df.T . BSX FNM ZTY CBY NYD TKT BFS NWO HZY NVL YEC TER PUL VRT NCT MUF FSK PEW LEN LUG PHI BGN TXR UYZ MET REU UEI ZVQ ZCD SYO BZC XRX ULT HQU WWT CIS TRO FFV MCA AWW ... OXR ACY GRI HCC PPT FIR ULI ZAB ZUJ SKN EEY SKI SEH NSC SHC EOP WXN LHB SBY IDT RWJ JTL JNE CSB DIG YFC DZF ERO BAX ERQ NYP AUX GRU UPP BOT USX JHI PME THA YAX . 0 539 | 512 | 457 | 455 | 397 | 396 | 343 | 341 | 314 | 311 | 290 | 281 | 260 | 221 | 210 | 208 | 187 | 178 | 169 | 145 | 140 | 138 | 132 | 114 | 111 | 102 | 99 | 99 | 85 | 84 | 81 | 78 | 76 | 70 | 66 | 63 | 63 | 56 | 55 | 54 | ... | 32 | 31 | 30 | 30 | 30 | 29 | 28 | 28 | 28 | 27 | 24 | 24 | 23 | 22 | 21 | 21 | 21 | 21 | 21 | 21 | 20 | 20 | 19 | 19 | 15 | 15 | 14 | 14 | 12 | 11 | 8 | 8 | 7 | 6 | 5 | 5 | 5 | 4 | 3 | 1 | . 1 rows × 94 columns . def plot_historic_dars(dars): rows, cols=2, int(.5+len(dars)/2) fig, ax = plt.subplots(nrows = rows, ncols = cols, figsize=(20, 8)) for i in range(rows): for j in range(cols): darwin=dars[cols*i+j] ax[i][j].plot(candles[candles.darwin==darwin].date.apply(lambda x: x.date()),candles[candles.darwin==darwin][&#39;open&#39;]-candles[candles.darwin==darwin][&#39;open&#39;][0], color=&#39;#ffd966&#39;) ax[i][j].set_title(darwin, color=&#39;#ffd966&#39;, loc=&#39;center&#39;, y=0.9) ax[i][j].set_ylim(-50,100) ax[i][j].set_frame_on(False) ax[i][j].set_xlabel(&#39;Periodo de Entrenamiento&#39;) ax[i][j].set_xticklabels([]) ax[i][j].axhline(y=0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) . . plot_historic_dars(df.index[:6]) . Descarga datos de los darwins con m&#225;s horas de m&#225;ximo score . Desde agosto 2020 hasta diciembre 2020 desde darwinex.com, utilizando ftp https://github.com/darwinex/darwinexapis/blob/master/darwinexapis/API/DarwinDataAnalyticsAPI/DWX_Data_Analytics_API.py . top=[&#39;BSX&#39;,&#39;FNM&#39;,&#39;ZTY&#39;,&#39;CBY&#39;,&#39;NYD&#39;,&#39;TKT&#39;,&#39;BFS&#39;,&#39;NWO&#39;,&#39;HZY&#39;,&#39;NVL&#39;,&#39;YEC&#39;,&#39;TER&#39;,&#39;PUL&#39;,&#39;VRT&#39;,&#39;NCT&#39;,&#39;MUF&#39;,&#39;FSK&#39;,&#39;PEW&#39;,&#39;LEN&#39;,&#39;LUG&#39;,&#39;PHI&#39;,&#39;BGN&#39;,&#39;TXR&#39;,&#39;UYZ&#39;,&#39;MET&#39;,&#39;REU&#39;,&#39;UEI&#39;,&#39;ZVQ&#39;, &#39;ZCD&#39;,&#39;SYO&#39;,&#39;BZC&#39;,&#39;XRX&#39;,&#39;ULT&#39;,&#39;HQU&#39;,&#39;WWT&#39;,&#39;CIS&#39;,&#39;TRO&#39;,&#39;FFV&#39;,&#39;MCA&#39;,&#39;AWW&#39;,&#39;GGR&#39;,&#39;AZG&#39;,&#39;GFJ&#39;,&#39;LWK&#39;,&#39;VVC&#39;,&#39;WFJ&#39;,&#39;OJG&#39;,&#39;OOS&#39;,&#39;SRI&#39;,&#39;LWE&#39;,&#39;HEO&#39;,&#39;RAT&#39;,&#39;TDD&#39;,&#39;ZXW&#39;,&#39;OXR&#39;,&#39;ACY&#39;, &#39;GRI&#39;,&#39;HCC&#39;,&#39;PPT&#39;,&#39;FIR&#39;,&#39;ULI&#39;,&#39;ZAB&#39;,&#39;ZUJ&#39;,&#39;SKN&#39;,&#39;EEY&#39;,&#39;SKI&#39;,&#39;SEH&#39;,&#39;NSC&#39;,&#39;SHC&#39;,&#39;EOP&#39;,&#39;WXN&#39;,&#39;LHB&#39;,&#39;SBY&#39;,&#39;IDT&#39;,&#39;RWJ&#39;,&#39;JTL&#39;] . Imports and server . from ftplib import FTP from tqdm import tqdm from io import BytesIO import gzip FTP_CRED = {&#39;username&#39;: USERNAME, &#39;password&#39;: PASSWORD, &#39;server&#39;: &quot;darwindata.darwinex.com&quot;, &#39;port&#39;: 21} dwx_ftp_hostname=FTP_CRED[&#39;server&#39;] dwx_ftp_user=FTP_CRED[&#39;username&#39;] dwx_ftp_pass=FTP_CRED[&#39;password&#39;] server = FTP(dwx_ftp_hostname) server.login(dwx_ftp_user, dwx_ftp_pass) . . &#39;230-Your bandwidth usage is restricted n230 OK. Current restricted directory is /&#39; . {DARWIN_TICKER}.{PRODUCTRISK}.{COLOUR}{PRODUCTID}_YYYY-MM-DD.HH.csv.gz &#39;former_var10&#39; . year=&#39;2020&#39; darwins_lst_dld=[&#39;FNM&#39;] for darwin in darwins_lst_dld: print(darwin) for month in [&#39;08&#39;,&#39;09&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;]: quote_files = [] server.retrlines(f&#39;NLST {darwin}/_{darwin}_former_var10/quotes/{year}-{month}/&#39;, quote_files.append) quote_files = [f&#39;{darwin}/_{darwin}_former_var10/quotes/{year}-{month}/{quote_file}&#39; for quote_file in quote_files] # Process tick data files tqdm.write(f&#39; n[KERNEL] {len(quote_files)} files retrieved.. post-processing now, please wait..&#39;, end=&#39;&#39;) ticks_df = pd.DataFrame() ticks_pbar = tqdm(quote_files, position=0, leave=True) for tick_file in ticks_pbar: # Clear / reinitialize buffer retbuf = BytesIO() server.retrbinary(f&quot;RETR {tick_file}&quot;, retbuf.write) retbuf.seek(0) # Extract data from BytesIO object ret = [line.strip().decode().split(&#39;,&#39;) for line in gzip.open(retbuf)] ticks_df = pd.concat([ticks_df, pd.DataFrame(ret[1:])], axis=0) # Clean up ticks_df.columns = [&#39;timestamp&#39;,&#39;quote&#39;] ticks_df.timestamp = ticks_df.timestamp.apply(pd.to_numeric) ticks_df.set_index(&#39;timestamp&#39;, drop=True, inplace=True) ticks_df.index = pd.to_datetime(ticks_df.index, unit=&#39;ms&#39;) ticks_df.quote = ticks_df.quote.apply(pd.to_numeric) ticks_df.dropna() fn=&#39;quotes/&#39;+darwin+&#39;_&#39;+year+&#39;_&#39;+month+&#39;_quotes.csv&#39; ticks_df.to_csv(&#39;./data/&#39;+fn) . FNM . 0%| | 0/228 [00:00&lt;?, ?it/s] . [KERNEL] 228 files retrieved.. post-processing now, please wait.. . 100%|██████████| 228/228 [01:41&lt;00:00, 2.24it/s] 0%| | 0/259 [00:00&lt;?, ?it/s] . [KERNEL] 259 files retrieved.. post-processing now, please wait.. . 100%|██████████| 259/259 [01:55&lt;00:00, 2.24it/s] 0%| | 0/288 [00:00&lt;?, ?it/s] . [KERNEL] 288 files retrieved.. post-processing now, please wait.. . 100%|██████████| 288/288 [02:09&lt;00:00, 2.23it/s] 0%| | 0/331 [00:00&lt;?, ?it/s] . [KERNEL] 331 files retrieved.. post-processing now, please wait.. . 100%|██████████| 331/331 [02:32&lt;00:00, 2.16it/s] 0%| | 0/225 [00:00&lt;?, ?it/s] . [KERNEL] 225 files retrieved.. post-processing now, please wait.. . 100%|██████████| 225/225 [01:39&lt;00:00, 2.27it/s] . new . darwins_lst_dld=[&#39;PPT&#39;] for darwin in darwins_lst_dld: #to do print(darwin) for month in [&#39;08&#39;,&#39;09&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;]: quote_files = [] server.retrlines(f&#39;NLST {darwin}/quotes/{year}-{month}/&#39;, quote_files.append) quote_files = [f&#39;{darwin}/quotes/{year}-{month}/{quote_file}&#39; for quote_file in quote_files] # Process tick data files tqdm.write(f&#39; n[KERNEL] {len(quote_files)} files retrieved.. post-processing now, please wait..&#39;, end=&#39;&#39;) ticks_df = pd.DataFrame() ticks_pbar = tqdm(quote_files, position=0, leave=True) for tick_file in ticks_pbar: # Clear / reinitialize buffer retbuf = BytesIO() server.retrbinary(f&quot;RETR {tick_file}&quot;, retbuf.write) retbuf.seek(0) # Extract data from BytesIO object ret = [line.strip().decode().split(&#39;,&#39;) for line in gzip.open(retbuf)] ticks_df = pd.concat([ticks_df, pd.DataFrame(ret[1:])], axis=0) # Clean up ticks_df.columns = [&#39;timestamp&#39;,&#39;quote&#39;] ticks_df.timestamp = ticks_df.timestamp.apply(pd.to_numeric) ticks_df.set_index(&#39;timestamp&#39;, drop=True, inplace=True) ticks_df.index = pd.to_datetime(ticks_df.index, unit=&#39;ms&#39;) ticks_df.quote = ticks_df.quote.apply(pd.to_numeric) ticks_df.dropna() fn=&#39;quotes/&#39;+darwin+&#39;_&#39;+year+&#39;_&#39;+month+&#39;_quotes.csv&#39; ticks_df.to_csv(&#39;./data/&#39;+fn) . PPT . 0%| | 0/511 [00:00&lt;?, ?it/s] . [KERNEL] 511 files retrieved.. post-processing now, please wait.. . 100%|██████████| 511/511 [04:06&lt;00:00, 2.07it/s] 0%| | 0/428 [00:00&lt;?, ?it/s] . [KERNEL] 428 files retrieved.. post-processing now, please wait.. . 100%|██████████| 428/428 [03:23&lt;00:00, 2.10it/s] 0%| | 0/26 [00:00&lt;?, ?it/s] . [KERNEL] 26 files retrieved.. post-processing now, please wait.. . 100%|██████████| 26/26 [00:10&lt;00:00, 2.54it/s] 0%| | 0/26 [00:00&lt;?, ?it/s] . [KERNEL] 26 files retrieved.. post-processing now, please wait.. . 100%|██████████| 26/26 [00:10&lt;00:00, 2.55it/s] 0%| | 0/26 [00:00&lt;?, ?it/s] . [KERNEL] 26 files retrieved.. post-processing now, please wait.. . 100%|██████████| 26/26 [00:10&lt;00:00, 2.55it/s] . Asigna porcentajes . Crea una cartera de los top 18 darwins e investiga su ratio de Sharpe variando porcentajes asignados . def create_hourly(fn, darwin): df=pd.read_csv(&#39;./data/quotes/&#39;+fn) df.timestamp=pd.to_datetime(df.timestamp) df[&#39;date&#39;]=df.timestamp.dt.date df[&#39;hour&#39;]=df.timestamp.dt.hour df1=df.groupby([&#39;date&#39;,&#39;hour&#39;]).agg({&#39;quote&#39;: [&#39;min&#39;,&#39;max&#39;,&#39;var&#39;,&#39;count&#39;,&#39;first&#39;,&#39;last&#39;]}).fillna(0) df1.columns=df1.columns.droplevel() df1[&#39;darwin&#39;]=darwin return df1 . Importa los datos . hourly = pd.DataFrame(columns=[&#39;min&#39;,&#39;max&#39;,&#39;var&#39;,&#39;count&#39;,&#39;first&#39;,&#39;last&#39;,&#39;score&#39;,&#39;darwin&#39;]) for darwin in top: for filename in [darwin+&#39;_2020_08_quotes.csv&#39;, darwin+&#39;_2020_09_quotes.csv&#39;, darwin+&#39;_2020_10_quotes.csv&#39;, darwin+&#39;_2020_11_quotes.csv&#39;, darwin+&#39;_2020_12_quotes.csv&#39;]: hourly=hourly.append(create_hourly(filename, darwin)) hourly[&#39;score&#39;]=round((hourly[&#39;last&#39;]-hourly[&#39;first&#39;])/np.sqrt(hourly[&#39;var&#39;]),4).fillna(0) hourly[&#39;return&#39;]=hourly[&#39;last&#39;]-hourly[&#39;first&#39;] hourly.reset_index(inplace=True) hourly.rename(columns={&#39;index&#39;:&#39;hour&#39;},inplace=True) hourly.hour=hourly.hour.apply(lambda x: pd.Timestamp(x[0])+pd.to_timedelta(x[1], unit=&#39;h&#39;)) print(hourly.shape) hourly.head() . (108844, 10) . hour min max var count first last score darwin return . 0 2020-08-02 21:00:00 | 126.4739 | 126.4739 | 0.000000 | 1 | 126.4739 | 126.4739 | 0.0000 | BSX | 0.0000 | . 1 2020-08-03 20:00:00 | 126.4538 | 126.6039 | 0.000996 | 1506 | 126.4659 | 126.5240 | 1.8409 | BSX | 0.0581 | . 2 2020-08-03 21:00:00 | 126.2886 | 126.7286 | 0.012971 | 57 | 126.4920 | 126.7286 | 2.0774 | BSX | 0.2366 | . 3 2020-08-04 21:00:00 | 126.7286 | 126.7286 | 0.000000 | 1 | 126.7286 | 126.7286 | 0.0000 | BSX | 0.0000 | . 4 2020-08-05 21:00:00 | 126.4861 | 126.8366 | 0.003487 | 543 | 126.7286 | 126.7779 | 0.8348 | BSX | 0.0493 | . df de rendimientos por hora por cada darwin desde el 18 agosto 2020 hasta el 24 diciembre 2020 . dars=sorted(hourly.darwin.unique()) lst=[hourly[hourly.darwin==dar][(hourly.hour&gt;=&#39;2020-08-18 00:00:00&#39;) &amp; (hourly.hour&lt;&#39;2020-12-24 22:00:00&#39;)][[&#39;hour&#39;,&#39;return&#39;]].rename(columns={&#39;return&#39;:dar}) for i,dar in enumerate(dars)] hly_rtns=pd.merge(lst[0], lst[1], how=&#39;outer&#39;) for i in range(2,len(dars)): hly_rtns=pd.merge(hly_rtns,lst[i], how=&#39;outer&#39;) hly_rtns.fillna(0., inplace=True) hly_rtns.head() . hour ACY AWW AZG BFS BGN BSX BZC CBY CIS EEY EOP FFV FIR FNM FSK GFJ GGR GRI HCC HEO HQU HZY IDT JTL LEN LHB LUG LWE LWK MCA MET MUF NCT NSC NVL NWO NYD OJG OOS OXR PEW PHI PPT PUL RAT REU RWJ SBY SEH SHC SKI SKN SRI SYO TDD TER TKT TRO TXR UEI ULI ULT UYZ VRT VVC WFJ WWT WXN XRX YEC ZAB ZCD ZTY ZUJ ZVQ ZXW . 0 2020-08-18 08:00:00 | -0.2046 | 0.0280 | -0.2541 | 0.0 | 0.0 | 0.0 | 0.0451 | 0.0764 | 0.0 | 0.0204 | -0.1279 | 0.3504 | 0.0 | 0.0 | 0.0 | -0.2471 | 0.0 | -0.3225 | 0.4445 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -0.4258 | 0.0 | -0.3640 | 0.1924 | 0.1630 | 0.0907 | -0.1216 | 0.0 | 0.0 | 0.2144 | 0.0 | 0.0 | 0.0 | 0.0 | -0.1580 | -0.2996 | 0.0 | 0.0 | -0.0489 | 0.0347 | 0.0000 | 0.0 | 0.0 | -0.1468 | -0.2239 | -0.5369 | 0.1110 | 0.0789 | 0.1928 | 0.3188 | 0.3515 | -0.0600 | 0.0 | -0.2799 | 0.0 | 0.0 | 0.0607 | 0.7122 | 0.0000 | -0.1237 | 0.0 | -0.3184 | 0.0 | 0.042 | 0.0 | 0.0125 | -1.0387 | 0.0641 | 0.0 | -0.1574 | -0.0757 | 0.1344 | . 1 2020-08-18 09:00:00 | -0.7715 | -0.0205 | -0.0352 | 0.0 | 0.0 | 0.0 | -0.0134 | 0.0346 | 0.0 | 0.0018 | 0.2048 | 0.2084 | 0.0 | 0.0 | 0.0 | 0.0683 | 0.0 | 0.0423 | 0.0228 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.1580 | 0.0 | 0.0246 | 0.0571 | -0.0628 | 0.0239 | -0.0345 | 0.0 | 0.0 | -0.2015 | 0.0 | 0.0 | 0.0 | 0.0 | -0.1657 | 0.2175 | 0.0 | 0.0 | 0.1492 | 0.0629 | 0.0000 | 0.0 | 0.0 | -0.0538 | -0.0820 | 0.0460 | 0.0350 | 0.1163 | -0.0742 | 0.7048 | 0.1127 | -0.0921 | 0.0 | -0.5873 | 0.0 | 0.0 | -0.0594 | -0.2741 | 0.0000 | 0.0460 | 0.0 | -0.6679 | 0.0 | 0.000 | 0.0 | -0.0682 | -0.2051 | 0.0091 | 0.0 | 0.0584 | 0.2911 | 0.0653 | . 2 2020-08-18 10:00:00 | -0.2072 | -0.0200 | 0.1754 | 0.0 | 0.0 | 0.0 | -0.0350 | 0.1176 | 0.0 | 0.0226 | -0.1140 | -0.4030 | 0.0 | 0.0 | 0.0 | 0.0297 | 0.0 | 0.1094 | 0.0920 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0559 | 0.0 | 0.2155 | 0.0632 | -0.0206 | -0.0736 | 0.0585 | 0.0 | 0.0 | -0.0541 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0236 | -0.0774 | 0.0 | 0.0 | -0.0878 | 0.0000 | 0.0000 | 0.0 | 0.0 | -0.0460 | 0.0943 | 0.4213 | 0.0459 | -0.4226 | -0.0244 | 0.0976 | -0.1895 | -0.0513 | 0.0 | 1.1642 | 0.0 | 0.0 | -0.0903 | -0.0901 | -0.0284 | 0.0162 | 0.0 | 1.3240 | 0.0 | 0.000 | 0.0 | 0.0551 | 0.5658 | -0.0328 | 0.0 | 0.0207 | -0.1894 | -0.1592 | . 3 2020-08-18 11:00:00 | 0.5182 | 0.0139 | 0.0390 | 0.0 | 0.0 | 0.0 | 0.0380 | -0.5722 | 0.0 | 0.0014 | -0.2086 | 0.1120 | 0.0 | 0.0 | 0.0 | -0.0700 | 0.0 | -0.7223 | 0.0110 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -0.1070 | 0.0 | -0.4118 | -0.0863 | 0.0421 | -0.0578 | -0.1186 | 0.0 | 0.0 | 0.1353 | 0.0 | 0.0 | 0.0 | 0.0 | -0.1538 | -0.2806 | 0.0 | 0.0 | -0.0575 | 0.0000 | 0.0000 | 0.0 | 0.0 | 0.0459 | 0.2790 | -0.6534 | -0.0834 | 0.6474 | 0.0498 | -0.2464 | -0.1914 | 0.0224 | 0.0 | -0.3642 | 0.0 | 0.0 | -0.0455 | 0.1842 | 0.5276 | -0.0311 | 0.0 | -0.4142 | 0.0 | 0.000 | 0.0 | -0.3371 | 0.3899 | 0.0122 | 0.0 | -0.0396 | 0.1832 | -0.0821 | . 4 2020-08-18 12:00:00 | 3.4317 | 0.0743 | -0.2758 | 0.0 | 0.0 | 0.0 | 0.0951 | -0.2141 | 0.0 | 0.1189 | -0.3103 | 0.3893 | 0.0 | 0.0 | 0.0 | -0.3064 | 0.0 | -0.6439 | 0.5604 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -0.7154 | 0.0 | -0.7258 | 0.5191 | 0.2783 | 0.1409 | -0.2989 | 0.0 | 0.0 | 0.9024 | 0.0 | 0.0 | 0.0 | 0.0 | 0.2012 | -0.3565 | 0.0 | 0.0 | -0.0169 | -0.0354 | -0.0161 | 0.0 | 0.0 | 0.0484 | 0.1981 | -0.4841 | 0.5091 | 0.6564 | 0.3292 | 0.6209 | -0.2148 | -0.0089 | 0.0 | -1.0961 | 0.0 | 0.0 | 0.3504 | 0.7548 | 0.5344 | -0.1306 | 0.0 | -1.2466 | 0.0 | 0.000 | 0.0 | 0.2408 | -1.1173 | 0.1225 | 0.0 | -0.2655 | 0.7707 | 0.4010 | . darwins con el rendimiento medio por hora más alto . means=pd.DataFrame(hly_rtns.mean(0), columns=[&#39;mean&#39;]) means.sort_values(&#39;mean&#39;, ascending=False).T . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version. &#34;&#34;&#34;Entry point for launching an IPython kernel. . ZVQ AZG BFS WFJ JTL HZY PHI NWO ZCD BGN UYZ TKT SRI EOP PUL ZAB CBY SEH HEO TXR MUF FIR UEI HCC VRT LHB LEN RAT NVL LUG NCT NSC PEW EEY OJG VVC ACY BSX TER IDT ZTY REU MCA ULI NYD FNM XRX HQU ZUJ YEC RWJ PPT OXR FSK TRO GRI WWT ULT SKN MET WXN LWK FFV GFJ OOS GGR SBY ZXW SHC AWW SYO LWE SKI TDD BZC CIS . mean 0.016565 | 0.013742 | 0.012682 | 0.012105 | 0.011587 | 0.011354 | 0.011118 | 0.010866 | 0.009491 | 0.009225 | 0.008431 | 0.008265 | 0.007448 | 0.007073 | 0.006668 | 0.006646 | 0.006444 | 0.006398 | 0.006105 | 0.006048 | 0.005723 | 0.005046 | 0.004573 | 0.004247 | 0.004117 | 0.004057 | 0.003757 | 0.003454 | 0.003395 | 0.003355 | 0.003305 | 0.003144 | 0.002914 | 0.002684 | 0.002597 | 0.002502 | 0.002462 | 0.002205 | 0.001809 | 0.001796 | 0.001619 | 0.001504 | 0.001236 | 0.001217 | 0.001191 | 0.001183 | 0.001126 | 0.001087 | 0.000908 | 0.000843 | 0.000571 | 0.00055 | 0.000469 | 0.000154 | 0.000086 | 0.00008 | 0.000067 | -0.000287 | -0.001176 | -0.00143 | -0.002289 | -0.002452 | -0.003837 | -0.004461 | -0.004783 | -0.005201 | -0.00663 | -0.006832 | -0.007273 | -0.009089 | -0.009591 | -0.010118 | -0.011254 | -0.01147 | -0.016548 | -0.017419 | . Historial de env&#237;os . results=[1.72, 1.58, 4.71, 1.7, 4.69, 4.81, 5.38, 5.29, 5.82, 6.18, 6.81, 6.72, 6.70, 6.81, 7.15, 7.94, 7.87, 7.79, 7.08, 7.98, 8.33, 8.29, 8.24, 8.17, 7.99, 8.18, 8.24] # quitando resultados NAN cuando la suma de la fila no era exactamente 1.0 fig, ax = plt.subplots(1, 1, figsize=(15, 8)) ax.plot(results, color=&#39;#ffe599&#39;) ax.set_title(&#39;Historial de envíos&#39;, fontsize=20) ax.set_xlabel(&#39;Envío&#39;, fontsize=14) ax.set_ylabel(&#39;CodaLab Leaderboard&#39;, fontsize=14) ax.set_ylim(0,10) ax.annotate(&#39;8.33&#39;, xy=(20, 8.33), xycoords=&#39;data&#39;, xytext=(0.8, 0.95), textcoords=&#39;axes fraction&#39;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05), horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;, fontsize=14 ) ax.axvline(x=20, ymin=0, ymax=1, color=&#39;red&#39;, alpha=.5, linestyle=&#39;dotted&#39;) ax.axhline(y=2, xmin=0, xmax=1, color=&#39;orange&#39;, alpha=.5, linestyle=&#39;dotted&#39;) ax.axhline(y=4, xmin=0, xmax=1, color=&#39;orange&#39;, alpha=.5, linestyle=&#39;dotted&#39;) ax.axhline(y=6, xmin=0, xmax=1, color=&#39;orange&#39;, alpha=.5, linestyle=&#39;dotted&#39;) ax.axhline(y=8, xmin=0, xmax=1, color=&#39;orange&#39;, alpha=.5, linestyle=&#39;dotted&#39;) for i, label in enumerate(range(27)): ax.annotate(label, (i, results[i]+.1)); plt.savefig(&#39;envios.png&#39;) . 2 - asignar a cada darwin 1/18 de la inversión, sin cambiar al largo del tiempo: &#39;ysharpe_ratio&#39;: 4.71, &#39;cumulative_return&#39;: 4.92 . | 6 - agrupar los 18 darwins en 3 grupos: bajo, medio y alto rendimiento. Menor peso por los bajos, más peso por los altos. &#39;ysharpe_ratio&#39;: 5.38, &#39;cumulative_return&#39;: 5.97 . | 10 - https://es.mathworks.com/help/finance/portfolio.estimatemaxsharperatio.html?s_tid=srchtitle con MATLAB instalado en el PC, quitando FNM, MET, NVL, REU, VRT y añadiendo ZTY, NYD, TKT, NWO, YEC. Optimizar en MATLAB. . | 15 - 3 rondas de top 22 darwins y luegor quitar 4 . | 20 - descargar datos por más darwins . | . Coge los primeros 22 Darwins del listado y pone sus medios de return,AssetMean y covarianzas AssetCovar en MATLAB https://www.mathworks.com/help/finance/portfolio.estimatemaxsharperatio.html . ‘Estimate Efficient Portfolio that Maximizes the Sharpe Ratio for a Portfolio Object with Semicontinuous and Cardinality Constraints’, . para seleccionar los mejores 18 activos de los 22. (Con más de 22 activos muchas veces no daba pesos porque no convergió.) . p = Portfolio(&#39;AssetMean&#39;, AssetMean, &#39;AssetCovar&#39;, AssetCovar); p = setDefaultConstraints(p); p = setMinMaxNumAssets(p, 18, 18); pesos = estimateMaxSharpeRatio(p,&#39;Method&#39;,&#39;iterative&#39;) ` . Seguí bajando el listado de darwins quitando los 4 darwins dejado el el rondo anterior y añadiendo 4 más para ver si mejoraba el resultado. . Si el resultado era mejor, lo puse en el Leaderboard. . Mi env&#237;o ganador . dars=[&#39;AZG&#39;,&#39;BFS&#39;,&#39;FSK&#39;,&#39;JTL&#39;,&#39;LUG&#39;,&#39;MUF&#39;,&#39;NCT&#39;,&#39;NWO&#39;,&#39;PEW&#39;,&#39;PHI&#39;,&#39;PUL&#39;,&#39;TER&#39;,&#39;TXR&#39;,&#39;UEI&#39;,&#39;UYZ&#39;,&#39;WWT&#39;,&#39;XRX&#39;,&#39;ZCD&#39;] wts=[0.0061,0.0109,0.1885,0.0079,0.0157,0.0077,0.019,0.0084,0.0046,0.0056,0.0099000000000001,0.0064,0.0153,0.0062,0.0026,0.65,0.0134,0.0218] fig , ax = plt.subplots(nrows = 6, ncols = 3, figsize=(20, 8)) rows,cols = 6,3 for i in range(rows): for j in range(cols): darwin=dars[cols*i+j] wt=&#39; &#39;+str(wts[cols*i+j]*100)[:5]+&#39;%&#39; ax[i][j].plot(range(len(hourly[hourly.darwin==darwin])),hourly[hourly.darwin==darwin][&#39;first&#39;]-hourly[hourly.darwin==darwin][&#39;first&#39;].to_list()[0], color=&#39;#ffd966&#39;) ax[i][j].set_ylim(-35,50) ax[i][j].set_title(darwin+wt) ax[i][j].set_frame_on(False) ax[i][j].axes.get_xaxis().set_visible(False) ax[i][j].axhline(y=0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) . Crea archivo de env&#237;o . # get &#39;eod_ts&#39; from the example submission file sub=pd.read_csv(&#39;./data/submission.csv&#39;) sub.eod_ts = pd.to_datetime(sub.eod_ts) # create new submission file new_sub=pd.DataFrame(columns=dars) new_sub[&#39;eod_ts&#39;]=sub.eod_ts new_sub.set_index(&#39;eod_ts&#39;, inplace=True) # % allocation for each darwin for i,dar in enumerate(dars): new_sub[dar]=wts[i] # check that all rows sum to 1.0 print(new_sub[dars].sum(1).sum()) assert new_sub[dars].sum(1).sum()==len(sub) # rename columns for col in new_sub.columns: new_sub=new_sub.rename(columns={col:&#39;allo_&#39;+col}) # save submission file new_sub.reset_index(inplace=True) new_sub.to_csv(&#39;./data/sub.csv&#39;,index=False) new_sub.head() . 2229.0 . eod_ts allo_AZG allo_BFS allo_FSK allo_JTL allo_LUG allo_MUF allo_NCT allo_NWO allo_PEW allo_PHI allo_PUL allo_TER allo_TXR allo_UEI allo_UYZ allo_WWT allo_XRX allo_ZCD . 0 2020-08-18 00:00:00 | 0.0061 | 0.0109 | 0.1885 | 0.0079 | 0.0157 | 0.0077 | 0.019 | 0.0084 | 0.0046 | 0.0056 | 0.0099 | 0.0064 | 0.0153 | 0.0062 | 0.0026 | 0.65 | 0.0134 | 0.0218 | . 1 2020-08-18 01:00:00 | 0.0061 | 0.0109 | 0.1885 | 0.0079 | 0.0157 | 0.0077 | 0.019 | 0.0084 | 0.0046 | 0.0056 | 0.0099 | 0.0064 | 0.0153 | 0.0062 | 0.0026 | 0.65 | 0.0134 | 0.0218 | . 2 2020-08-18 02:00:00 | 0.0061 | 0.0109 | 0.1885 | 0.0079 | 0.0157 | 0.0077 | 0.019 | 0.0084 | 0.0046 | 0.0056 | 0.0099 | 0.0064 | 0.0153 | 0.0062 | 0.0026 | 0.65 | 0.0134 | 0.0218 | . 3 2020-08-18 03:00:00 | 0.0061 | 0.0109 | 0.1885 | 0.0079 | 0.0157 | 0.0077 | 0.019 | 0.0084 | 0.0046 | 0.0056 | 0.0099 | 0.0064 | 0.0153 | 0.0062 | 0.0026 | 0.65 | 0.0134 | 0.0218 | . 4 2020-08-18 04:00:00 | 0.0061 | 0.0109 | 0.1885 | 0.0079 | 0.0157 | 0.0077 | 0.019 | 0.0084 | 0.0046 | 0.0056 | 0.0099 | 0.0064 | 0.0153 | 0.0062 | 0.0026 | 0.65 | 0.0134 | 0.0218 | . Relato: Lo que me deber&#237;a haber hecho . If ifs and ands were pots and pans... . &#161;Recuerde: el rendimiento pasado no es una gu&#237;a para el futuro! . Con los datos de Agosto 2020 a Diciembre 2020 descargado, no hace falta mirar los darwins con buen rendimiento anterior: hay que mirar el rendimiento de los darwins de Agosto 2020 a Diciembre 2020 . Descarga todos los datos de cotizaciones . len(darwins_lst) . 96 . hourly = pd.DataFrame(columns=[&#39;min&#39;,&#39;max&#39;,&#39;var&#39;,&#39;count&#39;,&#39;first&#39;,&#39;last&#39;,&#39;score&#39;,&#39;darwin&#39;]) for darwin in darwins_lst: for filename in [darwin+&#39;_2020_08_quotes.csv&#39;, darwin+&#39;_2020_09_quotes.csv&#39;, darwin+&#39;_2020_10_quotes.csv&#39;, darwin+&#39;_2020_11_quotes.csv&#39;, darwin+&#39;_2020_12_quotes.csv&#39;]: hourly=hourly.append(create_hourly(filename, darwin)) hourly[&#39;score&#39;]=round((hourly[&#39;last&#39;]-hourly[&#39;first&#39;])/np.sqrt(hourly[&#39;var&#39;]),4).fillna(0) hourly[&#39;return&#39;]=hourly[&#39;last&#39;]-hourly[&#39;first&#39;] hourly.reset_index(inplace=True) hourly.rename(columns={&#39;index&#39;:&#39;hour&#39;},inplace=True) hourly.hour=hourly.hour.apply(lambda x: pd.Timestamp(x[0])+pd.to_timedelta(x[1], unit=&#39;h&#39;)) print(hourly.shape) hourly.head() . (130910, 10) . hour min max var count first last score darwin return . 0 2020-08-02 21:00:00 | 126.4739 | 126.4739 | 0.000000 | 1 | 126.4739 | 126.4739 | 0.0000 | BSX | 0.0000 | . 1 2020-08-03 20:00:00 | 126.4538 | 126.6039 | 0.000996 | 1506 | 126.4659 | 126.5240 | 1.8409 | BSX | 0.0581 | . 2 2020-08-03 21:00:00 | 126.2886 | 126.7286 | 0.012971 | 57 | 126.4920 | 126.7286 | 2.0774 | BSX | 0.2366 | . 3 2020-08-04 21:00:00 | 126.7286 | 126.7286 | 0.000000 | 1 | 126.7286 | 126.7286 | 0.0000 | BSX | 0.0000 | . 4 2020-08-05 21:00:00 | 126.4861 | 126.8366 | 0.003487 | 543 | 126.7286 | 126.7779 | 0.8348 | BSX | 0.0493 | . dars=sorted(hourly.darwin.unique()) lst=[hourly[hourly.darwin==dar][(hourly.hour&gt;=&#39;2020-08-18 00:00:00&#39;) &amp; (hourly.hour&lt;&#39;2020-12-24 22:00:00&#39;)][[&#39;hour&#39;,&#39;return&#39;]].rename(columns={&#39;return&#39;:dar}) for i,dar in enumerate(dars)] hly_rtns=pd.merge(lst[0], lst[1], how=&#39;outer&#39;) for i in range(2,len(dars)): hly_rtns=pd.merge(hly_rtns,lst[i], how=&#39;outer&#39;) hly_rtns.fillna(0., inplace=True) hly_rtns.head() . hour ACY AUX AWW AZG BAX BFS BGN BOT BSX BZC CBY CIS CSB DIG DZF EEY EOP ERO ERQ FFV FIR FNM FSK GFJ GGR GRI GRU HCC HEO HQU HZY IDT JHI JNE JTL LEN LHB LUG LWE ... PPT PUL RAT REU RWJ SBY SEH SHC SKI SKN SRI SYO TDD TER THA TKT TMF TRO TXR UEI ULI ULT UPP USX UYZ VRT VVC WFJ WWT WXN XRX YAX YEC YFC ZAB ZCD ZTY ZUJ ZVQ ZXW . 0 2020-08-18 08:00:00 | -0.2046 | -0.3729 | 0.0280 | -0.2541 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0451 | 0.0764 | 0.0 | 0.0 | -0.1314 | 0.0 | 0.0204 | -0.1279 | 0.1415 | 0.0 | 0.3504 | 0.0 | 0.0 | 0.0 | -0.2471 | 0.0 | -0.3225 | 0.0 | 0.4445 | 0.0 | 0.0 | 0.0 | 0.0 | -0.1538 | -0.3362 | 0.0 | -0.4258 | 0.0 | -0.3640 | 0.1924 | ... | -0.0489 | 0.0347 | 0.0000 | 0.0 | 0.0 | -0.1468 | -0.2239 | -0.5369 | 0.1110 | 0.0789 | 0.1928 | 0.3188 | 0.3515 | -0.0600 | 0.0 | 0.0 | 0.0 | -0.2799 | 0.0 | 0.0 | 0.0607 | 0.7122 | 0.3243 | 0.0981 | 0.0000 | -0.1237 | 0.0 | -0.3184 | 0.0 | 0.042 | 0.0 | 0.0 | 0.0125 | 0.0179 | -1.0387 | 0.0641 | 0.0 | -0.1574 | -0.0757 | 0.1344 | . 1 2020-08-18 09:00:00 | -0.7715 | -1.3755 | -0.0205 | -0.0352 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -0.0134 | 0.0346 | 0.0 | 0.0 | 0.0487 | 0.0 | 0.0018 | 0.2048 | -0.0544 | 0.0 | 0.2084 | 0.0 | 0.0 | 0.0 | 0.0683 | 0.0 | 0.0423 | 0.0 | 0.0228 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0570 | 0.1824 | 0.0 | 0.1580 | 0.0 | 0.0246 | 0.0571 | ... | 0.1492 | 0.0629 | 0.0000 | 0.0 | 0.0 | -0.0538 | -0.0820 | 0.0460 | 0.0350 | 0.1163 | -0.0742 | 0.7048 | 0.1127 | -0.0921 | 0.0 | 0.0 | 0.0 | -0.5873 | 0.0 | 0.0 | -0.0594 | -0.2741 | -0.5190 | -0.0378 | 0.0000 | 0.0460 | 0.0 | -0.6679 | 0.0 | 0.000 | 0.0 | 0.0 | -0.0682 | 0.0043 | -0.2051 | 0.0091 | 0.0 | 0.0584 | 0.2911 | 0.0653 | . 2 2020-08-18 10:00:00 | -0.2072 | -0.3696 | -0.0200 | 0.1754 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -0.0350 | 0.1176 | 0.0 | 0.0 | 0.0173 | 0.0 | 0.0226 | -0.1140 | -0.0179 | 0.0 | -0.4030 | 0.0 | 0.0 | 0.0 | 0.0297 | 0.0 | 0.1094 | 0.0 | 0.0920 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0203 | 0.0241 | 0.0 | 0.0559 | 0.0 | 0.2155 | 0.0632 | ... | -0.0878 | 0.0000 | 0.0000 | 0.0 | 0.0 | -0.0460 | 0.0943 | 0.4213 | 0.0459 | -0.4226 | -0.0244 | 0.0976 | -0.1895 | -0.0513 | 0.0 | 0.0 | 0.0 | 1.1642 | 0.0 | 0.0 | -0.0903 | -0.0901 | 0.3634 | -0.0124 | -0.0284 | 0.0162 | 0.0 | 1.3240 | 0.0 | 0.000 | 0.0 | 0.0 | 0.0551 | -0.0154 | 0.5658 | -0.0328 | 0.0 | 0.0207 | -0.1894 | -0.1592 | . 3 2020-08-18 11:00:00 | 0.5182 | 0.9239 | 0.0139 | 0.0390 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0380 | -0.5722 | 0.0 | 0.0 | -0.0330 | 0.0 | 0.0014 | -0.2086 | 0.0366 | 0.0 | 0.1120 | 0.0 | 0.0 | 0.0 | -0.0700 | 0.0 | -0.7223 | 0.0 | 0.0110 | 0.0 | 0.0 | 0.0 | 0.0 | -0.0387 | -0.1421 | 0.0 | -0.1070 | 0.0 | -0.4118 | -0.0863 | ... | -0.0575 | 0.0000 | 0.0000 | 0.0 | 0.0 | 0.0459 | 0.2790 | -0.6534 | -0.0834 | 0.6474 | 0.0498 | -0.2464 | -0.1914 | 0.0224 | 0.0 | 0.0 | 0.0 | -0.3642 | 0.0 | 0.0 | -0.0455 | 0.1842 | -0.4543 | 0.0254 | 0.5276 | -0.0311 | 0.0 | -0.4142 | 0.0 | 0.000 | 0.0 | 0.0 | -0.3371 | 0.0237 | 0.3899 | 0.0122 | 0.0 | -0.0396 | 0.1832 | -0.0821 | . 4 2020-08-18 12:00:00 | 3.4317 | 6.1181 | 0.0743 | -0.2758 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0951 | -0.2141 | 0.0 | 0.0 | -0.2208 | 0.0 | 0.1189 | -0.3103 | 0.2415 | 0.0 | 0.3893 | 0.0 | 0.0 | 0.0 | -0.3064 | 0.0 | -0.6439 | 0.0 | 0.5604 | 0.0 | 0.0 | 0.0 | 0.0 | -0.2584 | -0.6364 | 0.0 | -0.7154 | 0.0 | -0.7258 | 0.5191 | ... | -0.0169 | -0.0354 | -0.0161 | 0.0 | 0.0 | 0.0484 | 0.1981 | -0.4841 | 0.5091 | 0.6564 | 0.3292 | 0.6209 | -0.2148 | -0.0089 | 0.0 | 0.0 | 0.0 | -1.0961 | 0.0 | 0.0 | 0.3504 | 0.7548 | 0.7006 | 0.1674 | 0.5344 | -0.1306 | 0.0 | -1.2466 | 0.0 | 0.000 | 0.0 | 0.0 | 0.2408 | 0.0241 | -1.1173 | 0.1225 | 0.0 | -0.2655 | 0.7707 | 0.4010 | . 5 rows × 97 columns . means=pd.DataFrame(hly_rtns.mean(0), columns=[&#39;mean&#39;]) means.sort_values(&#39;mean&#39;, ascending=False).T . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version. . ZVQ AZG BFS WFJ JTL HZY PHI NWO ERQ ZCD BGN UYZ TKT BOT SRI NYP EOP PUL ZAB AUX CBY SEH HEO TXR MUF FIR YFC UEI HCC VRT LHB JHI LEN RAT THA NVL LUG NCT NSC PEW ... XRX HQU MMY ZUJ YEC RWJ PPT OXR FSK TRO GRI WWT CSB UPP YAX PME ULT BAX DZF SKN MET JNE WXN LWK FFV GFJ TMF OOS GGR DIG SBY ZXW SHC AWW SYO LWE SKI TDD BZC CIS . mean 0.016565 | 0.013742 | 0.012682 | 0.012105 | 0.011587 | 0.011354 | 0.011118 | 0.010866 | 0.010481 | 0.009491 | 0.009225 | 0.008431 | 0.008265 | 0.007564 | 0.007448 | 0.007081 | 0.007073 | 0.006668 | 0.006646 | 0.006505 | 0.006444 | 0.006398 | 0.006105 | 0.006048 | 0.005723 | 0.005046 | 0.004877 | 0.004573 | 0.004247 | 0.004117 | 0.004057 | 0.003903 | 0.003757 | 0.003454 | 0.003443 | 0.003395 | 0.003355 | 0.003305 | 0.003144 | 0.002914 | ... | 0.001126 | 0.001087 | 0.000958 | 0.000908 | 0.000843 | 0.000571 | 0.00055 | 0.000469 | 0.000154 | 0.000086 | 0.00008 | 0.000067 | -0.000017 | -0.000071 | -0.000162 | -0.000268 | -0.000287 | -0.000928 | -0.000972 | -0.001176 | -0.00143 | -0.001942 | -0.002289 | -0.002452 | -0.003837 | -0.004461 | -0.004669 | -0.004783 | -0.005201 | -0.006178 | -0.00663 | -0.006832 | -0.007273 | -0.009089 | -0.009591 | -0.010118 | -0.011254 | -0.01147 | -0.016548 | -0.017419 | . 1 rows × 96 columns . Ronda 1: Escoge los darwins . def plot_dars(to_matlab): rows, cols = 2, 11 fig , ax = plt.subplots(nrows = rows, ncols = cols, figsize=(22, 8)) for i in range(rows): for j in range(cols): darwin=to_matlab[cols*i+j] color=&#39;#ffd966&#39; if darwin in drop: color=&#39;red&#39; ax[i][j].plot(hourly[hourly.darwin==darwin].hour,hourly[hourly.darwin==darwin][&#39;first&#39;]-hourly[hourly.darwin==darwin][&#39;first&#39;].to_list()[0], color=color) #print(min(hourly[hourly.darwin==darwin][&#39;first&#39;]-hourly[hourly.darwin==darwin][&#39;first&#39;].to_list()[0]),max(hourly[hourly.darwin==darwin][&#39;first&#39;]-hourly[hourly.darwin==darwin][&#39;first&#39;].to_list()[0])) ax[i][j].set_ylim(-40,55) ax[i][j].set_title(darwin, color=color) ax[i][j].set_frame_on(False) ax[i][j].axes.get_xaxis().set_visible(False) ax[i][j].axhline(y=0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) . to_matlab=sorted(means.sort_values(&#39;mean&#39;, ascending=False).index[:22]) print(&#39;darwins&#39;,to_matlab) print(&#39;AssetMean&#39;,[round(hly_rtns[darwin].mean(),6) for darwin in to_matlab]) print(&#39;AssetCovar&#39;,np.round(np.cov(np.array([hly_rtns[dar] for dar in to_matlab]),bias=True), 6)) . darwins [&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BGN&#39;, &#39;BOT&#39;, &#39;CBY&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;HZY&#39;, &#39;JTL&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;SEH&#39;, &#39;SRI&#39;, &#39;TKT&#39;, &#39;UYZ&#39;, &#39;WFJ&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] AssetMean [0.006505, 0.013742, 0.012682, 0.009225, 0.007564, 0.006444, 0.007073, 0.010481, 0.011354, 0.011587, 0.010866, 0.007081, 0.011118, 0.006668, 0.006398, 0.007448, 0.008265, 0.008431, 0.012105, 0.006646, 0.009491, 0.016565] AssetCovar [[ 3.48533e-01 5.05940e-02 5.21800e-03 -6.59900e-03 5.87800e-03 -1.07740e-02 -2.00280e-02 6.02300e-03 9.98000e-04 3.73200e-03 -3.78000e-04 -3.75060e-02 7.13300e-03 -3.89190e-02 -3.71900e-03 1.99870e-02 -5.02000e-04 2.82200e-03 6.57500e-03 -3.35100e-03 1.26030e-02 -1.22343e-01] [ 5.05940e-02 1.88605e-01 1.47700e-03 -3.25700e-03 8.50300e-03 3.20100e-03 -1.41290e-02 -2.33000e-04 5.86900e-03 -1.27110e-02 1.87500e-03 6.85000e-04 1.77140e-02 -1.58130e-02 -4.80700e-03 3.00870e-02 3.64300e-03 2.49600e-03 3.11860e-02 -3.89430e-02 5.33600e-03 -1.11429e-01] [ 5.21800e-03 1.47700e-03 6.66340e-02 4.20460e-02 4.46000e-04 9.65000e-04 3.80000e-05 2.01000e-04 3.86300e-03 1.01200e-03 4.32600e-03 -5.32900e-03 1.17200e-03 4.82800e-03 2.81400e-03 -5.70700e-03 3.43700e-03 3.39500e-03 -9.96800e-03 7.83600e-03 3.16200e-03 -2.52930e-02] [-6.59900e-03 -3.25700e-03 4.20460e-02 1.29205e-01 -1.00900e-03 2.03350e-02 4.90600e-03 -2.14000e-04 1.82850e-02 2.26200e-03 1.92080e-02 -1.96700e-03 -4.51600e-03 4.26400e-03 3.84700e-03 -6.72000e-04 1.69360e-02 4.14000e-03 -6.26100e-03 9.78800e-03 9.49100e-03 2.83310e-02] [ 5.87800e-03 8.50300e-03 4.46000e-04 -1.00900e-03 1.06046e-01 1.38000e-04 -1.02500e-03 2.23500e-03 -8.89000e-04 -6.60200e-03 -3.72000e-04 -6.02000e-04 3.39800e-03 -1.95600e-03 1.16600e-03 1.91800e-03 5.35000e-04 7.00300e-03 5.84400e-03 7.87000e-04 1.18000e-04 -3.93500e-03] [-1.07740e-02 3.20100e-03 9.65000e-04 2.03350e-02 1.38000e-04 1.08009e-01 2.94800e-03 -1.14500e-03 3.53590e-02 -8.20000e-05 1.84660e-02 -1.81700e-03 1.67900e-03 1.44100e-03 7.70000e-04 7.38800e-03 1.70800e-02 -2.55000e-04 1.07940e-02 -3.16000e-04 1.07730e-02 1.70860e-02] [-2.00280e-02 -1.41290e-02 3.80000e-05 4.90600e-03 -1.02500e-03 2.94800e-03 2.18290e-02 8.71000e-04 -3.95000e-04 2.24500e-03 2.74800e-03 1.62000e-04 -7.30800e-03 5.03400e-03 1.08920e-02 -1.06440e-02 3.88200e-03 -3.54400e-03 -9.04700e-03 1.80380e-02 1.36000e-04 4.48240e-02] [ 6.02300e-03 -2.33000e-04 2.01000e-04 -2.14000e-04 2.23500e-03 -1.14500e-03 8.71000e-04 5.24430e-02 6.20000e-05 -6.46000e-04 3.64000e-04 3.35700e-03 2.15400e-03 6.17700e-03 2.59300e-03 -2.81000e-03 1.02100e-03 1.80400e-03 -3.75100e-03 5.85000e-03 1.65500e-03 -4.96000e-04] [ 9.98000e-04 5.86900e-03 3.86300e-03 1.82850e-02 -8.89000e-04 3.53590e-02 -3.95000e-04 6.20000e-05 1.29009e-01 -7.88000e-04 2.33880e-02 3.29500e-03 1.03920e-02 2.81700e-03 -3.54500e-03 1.08230e-02 7.21600e-03 1.62000e-03 2.33790e-02 -2.91700e-03 1.71370e-02 1.85460e-02] [ 3.73200e-03 -1.27110e-02 1.01200e-03 2.26200e-03 -6.60200e-03 -8.20000e-05 2.24500e-03 -6.46000e-04 -7.88000e-04 1.10222e-01 3.20900e-03 1.25300e-03 -1.05300e-03 -2.37300e-03 1.00000e-03 -3.86800e-03 2.09500e-03 -1.53200e-03 -5.44200e-03 -1.99600e-03 9.63000e-04 4.39000e-03] [-3.78000e-04 1.87500e-03 4.32600e-03 1.92080e-02 -3.72000e-04 1.84660e-02 2.74800e-03 3.64000e-04 2.33880e-02 3.20900e-03 5.50620e-02 2.21300e-03 3.86400e-03 2.78200e-03 2.75500e-03 -1.50000e-04 3.63450e-02 1.66500e-03 1.28890e-02 5.16900e-03 7.19400e-03 1.75170e-02] [-3.75060e-02 6.85000e-04 -5.32900e-03 -1.96700e-03 -6.02000e-04 -1.81700e-03 1.62000e-04 3.35700e-03 3.29500e-03 1.25300e-03 2.21300e-03 6.59050e-02 -1.98100e-03 1.03200e-03 -2.12400e-03 2.45140e-02 2.11000e-03 -6.30000e-04 2.90000e-05 -3.31160e-02 -2.65400e-03 4.44790e-02] [ 7.13300e-03 1.77140e-02 1.17200e-03 -4.51600e-03 3.39800e-03 1.67900e-03 -7.30800e-03 2.15400e-03 1.03920e-02 -1.05300e-03 3.86400e-03 -1.98100e-03 1.45973e-01 4.73000e-04 -7.43500e-03 1.53310e-02 4.08200e-03 -2.19000e-04 1.51780e-01 -1.45050e-02 1.70500e-03 -4.98000e-02] [-3.89190e-02 -1.58130e-02 4.82800e-03 4.26400e-03 -1.95600e-03 1.44100e-03 5.03400e-03 6.17700e-03 2.81700e-03 -2.37300e-03 2.78200e-03 1.03200e-03 4.73000e-04 4.97750e-02 2.26000e-03 -1.01310e-02 4.43700e-03 -3.42100e-03 9.09000e-04 6.80400e-03 5.60000e-05 2.10800e-02] [-3.71900e-03 -4.80700e-03 2.81400e-03 3.84700e-03 1.16600e-03 7.70000e-04 1.08920e-02 2.59300e-03 -3.54500e-03 1.00000e-03 2.75500e-03 -2.12400e-03 -7.43500e-03 2.26000e-03 5.33940e-02 -1.60650e-02 5.88000e-03 -4.89300e-03 -7.62400e-03 4.34320e-02 1.56300e-03 1.85340e-02] [ 1.99870e-02 3.00870e-02 -5.70700e-03 -6.72000e-04 1.91800e-03 7.38800e-03 -1.06440e-02 -2.81000e-03 1.08230e-02 -3.86800e-03 -1.50000e-04 2.45140e-02 1.53310e-02 -1.01310e-02 -1.60650e-02 7.52170e-02 -5.31000e-04 1.05820e-02 2.95880e-02 -3.44600e-02 2.19100e-03 -1.48290e-02] [-5.02000e-04 3.64300e-03 3.43700e-03 1.69360e-02 5.35000e-04 1.70800e-02 3.88200e-03 1.02100e-03 7.21600e-03 2.09500e-03 3.63450e-02 2.11000e-03 4.08200e-03 4.43700e-03 5.88000e-03 -5.31000e-04 8.81210e-02 2.70000e-04 6.36200e-03 5.23200e-03 6.81800e-03 6.46800e-03] [ 2.82200e-03 2.49600e-03 3.39500e-03 4.14000e-03 7.00300e-03 -2.55000e-04 -3.54400e-03 1.80400e-03 1.62000e-03 -1.53200e-03 1.66500e-03 -6.30000e-04 -2.19000e-04 -3.42100e-03 -4.89300e-03 1.05820e-02 2.70000e-04 2.21354e-01 -8.03900e-03 1.06400e-03 3.21400e-03 6.52900e-03] [ 6.57500e-03 3.11860e-02 -9.96800e-03 -6.26100e-03 5.84400e-03 1.07940e-02 -9.04700e-03 -3.75100e-03 2.33790e-02 -5.44200e-03 1.28890e-02 2.90000e-05 1.51780e-01 9.09000e-04 -7.62400e-03 2.95880e-02 6.36200e-03 -8.03900e-03 3.69196e-01 -1.89600e-03 2.48500e-03 -7.75250e-02] [-3.35100e-03 -3.89430e-02 7.83600e-03 9.78800e-03 7.87000e-04 -3.16000e-04 1.80380e-02 5.85000e-03 -2.91700e-03 -1.99600e-03 5.16900e-03 -3.31160e-02 -1.45050e-02 6.80400e-03 4.34320e-02 -3.44600e-02 5.23200e-03 1.06400e-03 -1.89600e-03 1.62185e-01 4.22500e-03 5.40200e-03] [ 1.26030e-02 5.33600e-03 3.16200e-03 9.49100e-03 1.18000e-04 1.07730e-02 1.36000e-04 1.65500e-03 1.71370e-02 9.63000e-04 7.19400e-03 -2.65400e-03 1.70500e-03 5.60000e-05 1.56300e-03 2.19100e-03 6.81800e-03 3.21400e-03 2.48500e-03 4.22500e-03 2.74810e-02 -1.44800e-03] [-1.22343e-01 -1.11429e-01 -2.52930e-02 2.83310e-02 -3.93500e-03 1.70860e-02 4.48240e-02 -4.96000e-04 1.85460e-02 4.39000e-03 1.75170e-02 4.44790e-02 -4.98000e-02 2.10800e-02 1.85340e-02 -1.48290e-02 6.46800e-03 6.52900e-03 -7.75250e-02 5.40200e-03 -1.44800e-03 8.59706e-01]] . drop=[&#39;BGN&#39;,&#39;CBY&#39;,&#39;SRI&#39;,&#39;UYZ&#39;] wts=[0.0183,0.0485,0.0924,0.0353,0.1918,0.0837,0.0061,0.0604,0.0509,0.0553,0.0386,0.0686,0.0192,0.0605,0.0162,0.0203,0.1249,0.0090] dars=[&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;HZY&#39;, &#39;JTL&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;SEH&#39;, &#39;TKT&#39;, &#39;WFJ&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] plot_dars(to_matlab) plt.savefig(&#39;round1.png&#39;) . Ronda 2: Quita los darwins autocorrelacionados . to_matlab=sorted(means.sort_values(&#39;mean&#39;, ascending=False).index[:26]) to_matlab.remove(&#39;BGN&#39;) to_matlab.remove(&#39;CBY&#39;) to_matlab.remove(&#39;SRI&#39;) to_matlab.remove(&#39;UYZ&#39;) print(&#39;new:&#39;,sorted(means.sort_values(&#39;mean&#39;, ascending=False).index[22:26])) print(&#39;darwins&#39;,to_matlab) print(&#39;AssetMean&#39;,[round(hly_rtns[darwin].mean(),6) for darwin in to_matlab]) print(&#39;AssetCovar&#39;,np.round(np.cov(np.array([hly_rtns[dar] for dar in to_matlab]),bias=True), 6)) . new: [&#39;FIR&#39;, &#39;HEO&#39;, &#39;MUF&#39;, &#39;TXR&#39;] darwins [&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;FIR&#39;, &#39;HEO&#39;, &#39;HZY&#39;, &#39;JTL&#39;, &#39;MUF&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;SEH&#39;, &#39;TKT&#39;, &#39;TXR&#39;, &#39;WFJ&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] AssetMean [0.006505, 0.013742, 0.012682, 0.007564, 0.007073, 0.010481, 0.005046, 0.006105, 0.011354, 0.011587, 0.005723, 0.010866, 0.007081, 0.011118, 0.006668, 0.006398, 0.008265, 0.006048, 0.012105, 0.006646, 0.009491, 0.016565] AssetCovar [[ 3.48533e-01 5.05940e-02 5.21800e-03 5.87800e-03 -2.00280e-02 6.02300e-03 -2.48400e-03 -2.05000e-03 9.98000e-04 3.73200e-03 -2.27240e-02 -3.78000e-04 -3.75060e-02 7.13300e-03 -3.89190e-02 -3.71900e-03 -5.02000e-04 -1.42800e-03 6.57500e-03 -3.35100e-03 1.26030e-02 -1.22343e-01] [ 5.05940e-02 1.88605e-01 1.47700e-03 8.50300e-03 -1.41290e-02 -2.33000e-04 -4.87000e-04 1.09700e-03 5.86900e-03 -1.27110e-02 2.67000e-04 1.87500e-03 6.85000e-04 1.77140e-02 -1.58130e-02 -4.80700e-03 3.64300e-03 1.17100e-03 3.11860e-02 -3.89430e-02 5.33600e-03 -1.11429e-01] [ 5.21800e-03 1.47700e-03 6.66340e-02 4.46000e-04 3.80000e-05 2.01000e-04 1.30000e-05 -4.32500e-03 3.86300e-03 1.01200e-03 2.76400e-03 4.32600e-03 -5.32900e-03 1.17200e-03 4.82800e-03 2.81400e-03 3.43700e-03 1.33400e-03 -9.96800e-03 7.83600e-03 3.16200e-03 -2.52930e-02] [ 5.87800e-03 8.50300e-03 4.46000e-04 1.06046e-01 -1.02500e-03 2.23500e-03 -1.93400e-03 -1.01900e-03 -8.89000e-04 -6.60200e-03 -2.32400e-03 -3.72000e-04 -6.02000e-04 3.39800e-03 -1.95600e-03 1.16600e-03 5.35000e-04 2.75000e-04 5.84400e-03 7.87000e-04 1.18000e-04 -3.93500e-03] [-2.00280e-02 -1.41290e-02 3.80000e-05 -1.02500e-03 2.18290e-02 8.71000e-04 3.62000e-04 -9.66000e-04 -3.95000e-04 2.24500e-03 3.68900e-03 2.74800e-03 1.62000e-04 -7.30800e-03 5.03400e-03 1.08920e-02 3.88200e-03 7.60000e-05 -9.04700e-03 1.80380e-02 1.36000e-04 4.48240e-02] [ 6.02300e-03 -2.33000e-04 2.01000e-04 2.23500e-03 8.71000e-04 5.24430e-02 -1.00500e-03 -4.59800e-03 6.20000e-05 -6.46000e-04 -8.38000e-04 3.64000e-04 3.35700e-03 2.15400e-03 6.17700e-03 2.59300e-03 1.02100e-03 -2.97000e-04 -3.75100e-03 5.85000e-03 1.65500e-03 -4.96000e-04] [-2.48400e-03 -4.87000e-04 1.30000e-05 -1.93400e-03 3.62000e-04 -1.00500e-03 7.19900e-03 2.24700e-03 7.00000e-06 1.48100e-03 4.80000e-04 5.00000e-06 8.43000e-04 2.26000e-03 9.72000e-04 -1.00000e-05 2.19000e-04 3.22000e-04 8.62000e-04 -1.46700e-03 2.33000e-04 3.25700e-03] [-2.05000e-03 1.09700e-03 -4.32500e-03 -1.01900e-03 -9.66000e-04 -4.59800e-03 2.24700e-03 1.88411e-01 4.63000e-04 1.72310e-02 2.00000e-05 3.75500e-03 2.17900e-03 5.04000e-03 4.70000e-04 -4.48800e-03 -4.74000e-04 6.51000e-04 2.03900e-03 -1.91200e-03 4.65000e-04 -4.02000e-03] [ 9.98000e-04 5.86900e-03 3.86300e-03 -8.89000e-04 -3.95000e-04 6.20000e-05 7.00000e-06 4.63000e-04 1.29009e-01 -7.88000e-04 1.32600e-03 2.33880e-02 3.29500e-03 1.03920e-02 2.81700e-03 -3.54500e-03 7.21600e-03 6.04300e-03 2.33790e-02 -2.91700e-03 1.71370e-02 1.85460e-02] [ 3.73200e-03 -1.27110e-02 1.01200e-03 -6.60200e-03 2.24500e-03 -6.46000e-04 1.48100e-03 1.72310e-02 -7.88000e-04 1.10222e-01 -6.82000e-04 3.20900e-03 1.25300e-03 -1.05300e-03 -2.37300e-03 1.00000e-03 2.09500e-03 4.56000e-04 -5.44200e-03 -1.99600e-03 9.63000e-04 4.39000e-03] [-2.27240e-02 2.67000e-04 2.76400e-03 -2.32400e-03 3.68900e-03 -8.38000e-04 4.80000e-04 2.00000e-05 1.32600e-03 -6.82000e-04 3.75980e-02 3.32800e-03 1.98370e-02 -1.01700e-02 5.82800e-03 -3.17000e-04 3.39000e-03 6.70000e-05 -9.38400e-03 -2.32100e-03 -2.06000e-04 2.76830e-02] [-3.78000e-04 1.87500e-03 4.32600e-03 -3.72000e-04 2.74800e-03 3.64000e-04 5.00000e-06 3.75500e-03 2.33880e-02 3.20900e-03 3.32800e-03 5.50620e-02 2.21300e-03 3.86400e-03 2.78200e-03 2.75500e-03 3.63450e-02 4.21200e-03 1.28890e-02 5.16900e-03 7.19400e-03 1.75170e-02] [-3.75060e-02 6.85000e-04 -5.32900e-03 -6.02000e-04 1.62000e-04 3.35700e-03 8.43000e-04 2.17900e-03 3.29500e-03 1.25300e-03 1.98370e-02 2.21300e-03 6.59050e-02 -1.98100e-03 1.03200e-03 -2.12400e-03 2.11000e-03 2.86000e-04 2.90000e-05 -3.31160e-02 -2.65400e-03 4.44790e-02] [ 7.13300e-03 1.77140e-02 1.17200e-03 3.39800e-03 -7.30800e-03 2.15400e-03 2.26000e-03 5.04000e-03 1.03920e-02 -1.05300e-03 -1.01700e-02 3.86400e-03 -1.98100e-03 1.45973e-01 4.73000e-04 -7.43500e-03 4.08200e-03 1.32300e-03 1.51780e-01 -1.45050e-02 1.70500e-03 -4.98000e-02] [-3.89190e-02 -1.58130e-02 4.82800e-03 -1.95600e-03 5.03400e-03 6.17700e-03 9.72000e-04 4.70000e-04 2.81700e-03 -2.37300e-03 5.82800e-03 2.78200e-03 1.03200e-03 4.73000e-04 4.97750e-02 2.26000e-03 4.43700e-03 2.80000e-05 9.09000e-04 6.80400e-03 5.60000e-05 2.10800e-02] [-3.71900e-03 -4.80700e-03 2.81400e-03 1.16600e-03 1.08920e-02 2.59300e-03 -1.00000e-05 -4.48800e-03 -3.54500e-03 1.00000e-03 -3.17000e-04 2.75500e-03 -2.12400e-03 -7.43500e-03 2.26000e-03 5.33940e-02 5.88000e-03 2.30000e-05 -7.62400e-03 4.34320e-02 1.56300e-03 1.85340e-02] [-5.02000e-04 3.64300e-03 3.43700e-03 5.35000e-04 3.88200e-03 1.02100e-03 2.19000e-04 -4.74000e-04 7.21600e-03 2.09500e-03 3.39000e-03 3.63450e-02 2.11000e-03 4.08200e-03 4.43700e-03 5.88000e-03 8.81210e-02 2.25000e-03 6.36200e-03 5.23200e-03 6.81800e-03 6.46800e-03] [-1.42800e-03 1.17100e-03 1.33400e-03 2.75000e-04 7.60000e-05 -2.97000e-04 3.22000e-04 6.51000e-04 6.04300e-03 4.56000e-04 6.70000e-05 4.21200e-03 2.86000e-04 1.32300e-03 2.80000e-05 2.30000e-05 2.25000e-03 2.40260e-02 3.04400e-03 -7.50000e-05 9.28000e-04 6.25400e-03] [ 6.57500e-03 3.11860e-02 -9.96800e-03 5.84400e-03 -9.04700e-03 -3.75100e-03 8.62000e-04 2.03900e-03 2.33790e-02 -5.44200e-03 -9.38400e-03 1.28890e-02 2.90000e-05 1.51780e-01 9.09000e-04 -7.62400e-03 6.36200e-03 3.04400e-03 3.69196e-01 -1.89600e-03 2.48500e-03 -7.75250e-02] [-3.35100e-03 -3.89430e-02 7.83600e-03 7.87000e-04 1.80380e-02 5.85000e-03 -1.46700e-03 -1.91200e-03 -2.91700e-03 -1.99600e-03 -2.32100e-03 5.16900e-03 -3.31160e-02 -1.45050e-02 6.80400e-03 4.34320e-02 5.23200e-03 -7.50000e-05 -1.89600e-03 1.62185e-01 4.22500e-03 5.40200e-03] [ 1.26030e-02 5.33600e-03 3.16200e-03 1.18000e-04 1.36000e-04 1.65500e-03 2.33000e-04 4.65000e-04 1.71370e-02 9.63000e-04 -2.06000e-04 7.19400e-03 -2.65400e-03 1.70500e-03 5.60000e-05 1.56300e-03 6.81800e-03 9.28000e-04 2.48500e-03 4.22500e-03 2.74810e-02 -1.44800e-03] [-1.22343e-01 -1.11429e-01 -2.52930e-02 -3.93500e-03 4.48240e-02 -4.96000e-04 3.25700e-03 -4.02000e-03 1.85460e-02 4.39000e-03 2.76830e-02 1.75170e-02 4.44790e-02 -4.98000e-02 2.10800e-02 1.85340e-02 6.46800e-03 6.25400e-03 -7.75250e-02 5.40200e-03 -1.44800e-03 8.59706e-01]] . drop=[&#39;HZY&#39;,&#39;WFJ&#39;,&#39;SEH&#39;,&#39;TKT&#39;] dars=[&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;FIR&#39;, &#39;HEO&#39;, &#39;JTL&#39;, &#39;MUF&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;TXR&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] wts=[0.0173,0.0379,0.0629,0.0309,0.1232,0.0654,0.2552,0.0076,0.0378,0.0235,0.0329,0.0487,0.0272,0.0383,0.0762,0.0165,0.0930,0.0055] plot_dars(to_matlab) plt.savefig(&#39;round2.png&#39;) . Prueba de concepto: Codalab Score, 7 abril: 10.30 . Ronda 3: Rinse and repeat . to_matlab=sorted(means.sort_values(&#39;mean&#39;, ascending=False).index[:30]) to_matlab.remove(&#39;BGN&#39;) to_matlab.remove(&#39;CBY&#39;) to_matlab.remove(&#39;SRI&#39;) to_matlab.remove(&#39;UYZ&#39;) to_matlab.remove(&#39;HZY&#39;) to_matlab.remove(&#39;WFJ&#39;) to_matlab.remove(&#39;SEH&#39;) to_matlab.remove(&#39;TKT&#39;) print(&#39;new:&#39;,sorted(means.sort_values(&#39;mean&#39;, ascending=False).index[26:30])) print(&#39;darwins&#39;,to_matlab) print(&#39;AssetMean&#39;,[round(hly_rtns[darwin].mean(),6) for darwin in to_matlab]) print(&#39;AssetCovar&#39;,np.round(np.cov(np.array([hly_rtns[dar] for dar in to_matlab]),bias=True), 6)) . new: [&#39;HCC&#39;, &#39;UEI&#39;, &#39;VRT&#39;, &#39;YFC&#39;] darwins [&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;FIR&#39;, &#39;HCC&#39;, &#39;HEO&#39;, &#39;JTL&#39;, &#39;MUF&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;TXR&#39;, &#39;UEI&#39;, &#39;VRT&#39;, &#39;YFC&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] AssetMean [0.006505, 0.013742, 0.012682, 0.007564, 0.007073, 0.010481, 0.005046, 0.004247, 0.006105, 0.011587, 0.005723, 0.010866, 0.007081, 0.011118, 0.006668, 0.006048, 0.004573, 0.004117, 0.004877, 0.006646, 0.009491, 0.016565] AssetCovar [[ 3.48533e-01 5.05940e-02 5.21800e-03 5.87800e-03 -2.00280e-02 6.02300e-03 -2.48400e-03 1.08600e-02 -2.05000e-03 3.73200e-03 -2.27240e-02 -3.78000e-04 -3.75060e-02 7.13300e-03 -3.89190e-02 -1.42800e-03 -7.14000e-04 1.72140e-02 4.04300e-03 -3.35100e-03 1.26030e-02 -1.22343e-01] [ 5.05940e-02 1.88605e-01 1.47700e-03 8.50300e-03 -1.41290e-02 -2.33000e-04 -4.87000e-04 2.15010e-02 1.09700e-03 -1.27110e-02 2.67000e-04 1.87500e-03 6.85000e-04 1.77140e-02 -1.58130e-02 1.17100e-03 -1.85900e-03 3.25430e-02 1.32740e-02 -3.89430e-02 5.33600e-03 -1.11429e-01] [ 5.21800e-03 1.47700e-03 6.66340e-02 4.46000e-04 3.80000e-05 2.01000e-04 1.30000e-05 -2.33000e-04 -4.32500e-03 1.01200e-03 2.76400e-03 4.32600e-03 -5.32900e-03 1.17200e-03 4.82800e-03 1.33400e-03 4.14800e-03 5.63600e-03 2.83300e-03 7.83600e-03 3.16200e-03 -2.52930e-02] [ 5.87800e-03 8.50300e-03 4.46000e-04 1.06046e-01 -1.02500e-03 2.23500e-03 -1.93400e-03 5.03000e-03 -1.01900e-03 -6.60200e-03 -2.32400e-03 -3.72000e-04 -6.02000e-04 3.39800e-03 -1.95600e-03 2.75000e-04 -1.04200e-03 2.80000e-04 3.81900e-03 7.87000e-04 1.18000e-04 -3.93500e-03] [-2.00280e-02 -1.41290e-02 3.80000e-05 -1.02500e-03 2.18290e-02 8.71000e-04 3.62000e-04 -2.63100e-03 -9.66000e-04 2.24500e-03 3.68900e-03 2.74800e-03 1.62000e-04 -7.30800e-03 5.03400e-03 7.60000e-05 2.41000e-03 -1.52200e-03 -4.45400e-03 1.80380e-02 1.36000e-04 4.48240e-02] [ 6.02300e-03 -2.33000e-04 2.01000e-04 2.23500e-03 8.71000e-04 5.24430e-02 -1.00500e-03 -2.18400e-03 -4.59800e-03 -6.46000e-04 -8.38000e-04 3.64000e-04 3.35700e-03 2.15400e-03 6.17700e-03 -2.97000e-04 6.10000e-04 2.39500e-03 -2.95000e-04 5.85000e-03 1.65500e-03 -4.96000e-04] [-2.48400e-03 -4.87000e-04 1.30000e-05 -1.93400e-03 3.62000e-04 -1.00500e-03 7.19900e-03 1.05200e-03 2.24700e-03 1.48100e-03 4.80000e-04 5.00000e-06 8.43000e-04 2.26000e-03 9.72000e-04 3.22000e-04 -4.13000e-04 -5.47000e-04 5.80000e-05 -1.46700e-03 2.33000e-04 3.25700e-03] [ 1.08600e-02 2.15010e-02 -2.33000e-04 5.03000e-03 -2.63100e-03 -2.18400e-03 1.05200e-03 6.56330e-02 4.29000e-03 -5.74000e-04 -2.27600e-03 8.26000e-04 -5.42500e-03 7.86100e-03 -3.31400e-03 3.93000e-04 -3.10100e-03 9.30500e-03 3.66400e-03 -1.17730e-02 7.95000e-04 -6.47800e-03] [-2.05000e-03 1.09700e-03 -4.32500e-03 -1.01900e-03 -9.66000e-04 -4.59800e-03 2.24700e-03 4.29000e-03 1.88411e-01 1.72310e-02 2.00000e-05 3.75500e-03 2.17900e-03 5.04000e-03 4.70000e-04 6.51000e-04 -2.14400e-03 -7.46800e-03 -2.94500e-03 -1.91200e-03 4.65000e-04 -4.02000e-03] [ 3.73200e-03 -1.27110e-02 1.01200e-03 -6.60200e-03 2.24500e-03 -6.46000e-04 1.48100e-03 -5.74000e-04 1.72310e-02 1.10222e-01 -6.82000e-04 3.20900e-03 1.25300e-03 -1.05300e-03 -2.37300e-03 4.56000e-04 -3.55500e-03 5.70200e-03 8.70000e-04 -1.99600e-03 9.63000e-04 4.39000e-03] [-2.27240e-02 2.67000e-04 2.76400e-03 -2.32400e-03 3.68900e-03 -8.38000e-04 4.80000e-04 -2.27600e-03 2.00000e-05 -6.82000e-04 3.75980e-02 3.32800e-03 1.98370e-02 -1.01700e-02 5.82800e-03 6.70000e-05 1.20100e-03 4.14000e-04 -3.97100e-03 -2.32100e-03 -2.06000e-04 2.76830e-02] [-3.78000e-04 1.87500e-03 4.32600e-03 -3.72000e-04 2.74800e-03 3.64000e-04 5.00000e-06 8.26000e-04 3.75500e-03 3.20900e-03 3.32800e-03 5.50620e-02 2.21300e-03 3.86400e-03 2.78200e-03 4.21200e-03 9.69000e-04 2.10500e-03 -3.04000e-04 5.16900e-03 7.19400e-03 1.75170e-02] [-3.75060e-02 6.85000e-04 -5.32900e-03 -6.02000e-04 1.62000e-04 3.35700e-03 8.43000e-04 -5.42500e-03 2.17900e-03 1.25300e-03 1.98370e-02 2.21300e-03 6.59050e-02 -1.98100e-03 1.03200e-03 2.86000e-04 -2.79000e-03 -6.22000e-04 -4.85700e-03 -3.31160e-02 -2.65400e-03 4.44790e-02] [ 7.13300e-03 1.77140e-02 1.17200e-03 3.39800e-03 -7.30800e-03 2.15400e-03 2.26000e-03 7.86100e-03 5.04000e-03 -1.05300e-03 -1.01700e-02 3.86400e-03 -1.98100e-03 1.45973e-01 4.73000e-04 1.32300e-03 -1.03000e-04 3.93900e-03 -5.45000e-04 -1.45050e-02 1.70500e-03 -4.98000e-02] [-3.89190e-02 -1.58130e-02 4.82800e-03 -1.95600e-03 5.03400e-03 6.17700e-03 9.72000e-04 -3.31400e-03 4.70000e-04 -2.37300e-03 5.82800e-03 2.78200e-03 1.03200e-03 4.73000e-04 4.97750e-02 2.80000e-05 1.30000e-03 -6.17100e-03 -1.45000e-03 6.80400e-03 5.60000e-05 2.10800e-02] [-1.42800e-03 1.17100e-03 1.33400e-03 2.75000e-04 7.60000e-05 -2.97000e-04 3.22000e-04 3.93000e-04 6.51000e-04 4.56000e-04 6.70000e-05 4.21200e-03 2.86000e-04 1.32300e-03 2.80000e-05 2.40260e-02 6.51000e-04 4.08000e-04 -9.30000e-05 -7.50000e-05 9.28000e-04 6.25400e-03] [-7.14000e-04 -1.85900e-03 4.14800e-03 -1.04200e-03 2.41000e-03 6.10000e-04 -4.13000e-04 -3.10100e-03 -2.14400e-03 -3.55500e-03 1.20100e-03 9.69000e-04 -2.79000e-03 -1.03000e-04 1.30000e-03 6.51000e-04 4.65900e-02 1.05200e-03 1.78200e-03 4.35700e-03 -1.92000e-03 -6.73000e-04] [ 1.72140e-02 3.25430e-02 5.63600e-03 2.80000e-04 -1.52200e-03 2.39500e-03 -5.47000e-04 9.30500e-03 -7.46800e-03 5.70200e-03 4.14000e-04 2.10500e-03 -6.22000e-04 3.93900e-03 -6.17100e-03 4.08000e-04 1.05200e-03 1.23841e-01 1.36600e-03 -6.04900e-03 2.38400e-03 -1.73490e-02] [ 4.04300e-03 1.32740e-02 2.83300e-03 3.81900e-03 -4.45400e-03 -2.95000e-04 5.80000e-05 3.66400e-03 -2.94500e-03 8.70000e-04 -3.97100e-03 -3.04000e-04 -4.85700e-03 -5.45000e-04 -1.45000e-03 -9.30000e-05 1.78200e-03 1.36600e-03 2.54330e-02 1.33900e-03 4.36000e-04 -2.41130e-02] [-3.35100e-03 -3.89430e-02 7.83600e-03 7.87000e-04 1.80380e-02 5.85000e-03 -1.46700e-03 -1.17730e-02 -1.91200e-03 -1.99600e-03 -2.32100e-03 5.16900e-03 -3.31160e-02 -1.45050e-02 6.80400e-03 -7.50000e-05 4.35700e-03 -6.04900e-03 1.33900e-03 1.62185e-01 4.22500e-03 5.40200e-03] [ 1.26030e-02 5.33600e-03 3.16200e-03 1.18000e-04 1.36000e-04 1.65500e-03 2.33000e-04 7.95000e-04 4.65000e-04 9.63000e-04 -2.06000e-04 7.19400e-03 -2.65400e-03 1.70500e-03 5.60000e-05 9.28000e-04 -1.92000e-03 2.38400e-03 4.36000e-04 4.22500e-03 2.74810e-02 -1.44800e-03] [-1.22343e-01 -1.11429e-01 -2.52930e-02 -3.93500e-03 4.48240e-02 -4.96000e-04 3.25700e-03 -6.47800e-03 -4.02000e-03 4.39000e-03 2.76830e-02 1.75170e-02 4.44790e-02 -4.98000e-02 2.10800e-02 6.25400e-03 -6.73000e-04 -1.73490e-02 -2.41130e-02 5.40200e-03 -1.44800e-03 8.59706e-01]] . drop=[&#39;HCC&#39;,&#39;JTL&#39;,&#39;MUF&#39;,&#39;VRT&#39;] dars=[&#39;AUX&#39;, &#39;AZG&#39;, &#39;BFS&#39;, &#39;BOT&#39;, &#39;EOP&#39;, &#39;ERQ&#39;, &#39;FIR&#39;, &#39;HEO&#39;, &#39;NWO&#39;, &#39;NYP&#39;, &#39;PHI&#39;, &#39;PUL&#39;, &#39;TXR&#39;, &#39;UEI&#39;, &#39;YFC&#39;, &#39;ZAB&#39;, &#39;ZCD&#39;, &#39;ZVQ&#39;] wts=[0.0165,0.0340,0.0680,0.0242,0.1321,0.0676,0.2115,0.0117,0.0385,0.0568,0.0292,0.0328,0.0646,0.0218,0.0718,0.0124,0.0980,0.0084] plot_dars(to_matlab) . Diferencias entre los Darwins de 8,3 y los Darwins de 10,3 . def plot_train_and_test_dars(dars, color=&#39;black&#39;): rows, cols=2, int(.5+len(dars)/2) fig, ax = plt.subplots(nrows = rows, ncols = cols, figsize=(20, 8)) for i in range(rows): for j in range(cols): darwin=dars[cols*i+j] ax[i][j].plot(candles[candles.darwin==darwin].date.apply(lambda x: x.date()).to_list()+hourly[hourly.darwin==darwin].hour.apply(lambda x: x.date()).to_list(), (candles[candles.darwin==darwin][&#39;open&#39;]-candles[candles.darwin==darwin][&#39;open&#39;][0]).to_list()+(hourly[hourly.darwin==darwin][&#39;first&#39;]-candles[candles.darwin==darwin][&#39;open&#39;].to_list()[0]).to_list(), color=color) ax[i][j].set_title(darwin, color=color, loc=&#39;center&#39;, y=0.8) ax[i][j].set_ylim(-50,170) ax[i][j].set_frame_on(False) ax[i][j].set_xlabel(&#39;Entrenamiento | Test&#39;) ax[i][j].set_xticklabels([]) ax[i][j].axvline(x=hourly[hourly.darwin==darwin].hour.apply(lambda x: x.date()).to_list()[0], color=&#39;grey&#39;, linestyle=&#39;dashed&#39;) ax[i][j].axhline(y=0, color=&#39;grey&#39;, linestyle=&#39;dotted&#39;) . dars=[&#39;AUX&#39;,&#39;BOT&#39;,&#39;EOP&#39;,&#39;ERQ&#39;,&#39;FIR&#39;,&#39;HEO&#39;,&#39;MUF&#39;,&#39;NYP&#39;,&#39;ZAB&#39;,&#39;ZVQ&#39;] plot_train_and_test_dars(dars,color=&#39;#ffd966&#39;) plt.savefig(&#39;train_test.png&#39;) . dars=[&#39;FSK&#39;,&#39;LUG&#39;,&#39;MUF&#39;,&#39;NCT&#39;,&#39;PEW&#39;,&#39;TER&#39;,&#39;UEI&#39;,&#39;UYZ&#39;,&#39;WWT&#39;,&#39;XRX&#39;] plot_train_and_test_dars(dars,color=&#39;red&#39;) . dars=[&#39;AZG&#39;,&#39;BFS&#39;,&#39;JTL&#39;,&#39;NWO&#39;,&#39;PHI&#39;,&#39;PUL&#39;,&#39;TXR&#39;,&#39;ZCD&#39;] plot_train_and_test_dars(dars) . Reflexiones . El hecho de repensar lo que hice por el reto con la idea de explicarlo a otros resultó ser una forma estupenda de revelar los fallos. | ¡Para y piensa! Haz un &#39;time-out&#39; para repensar. Vale la pena revisar todos los puntos de decisión y replantar el problema. | ¡Ten paciencia! espera el tiempo de descarga de todos los datos, aunque sean horas | espera a que el algoritmo de MATLAB converja, invertas horas en hacerlo | . | ¡Concéntrate en una sola tarea! Todos tenemos que lidiar con muchas tareas. | Necesitas tener la cabeza despejada. | Es mejor trabajar secuencialmente que en paralelo (no soy un GPU). | . | Cree en ti mismo. | Aprendemos haciendo. | ... | . También he conseguido el cuarto puesto, junto con #javic y #agnprz, en el reto de visión por ordenador y el sexto puesto en el reto de PLN. . Si tienes datos a entender, estaré encantada de ayudarte 😊 . Gracias a SPAIN-AI, Darwinex y los demás participantes. . .",
            "url": "https://alisondavey.github.io/fastpages/spain-ai/time_series/competition/2021/05/08/RetoSeriesTemporales.html",
            "relUrl": "/spain-ai/time_series/competition/2021/05/08/RetoSeriesTemporales.html",
            "date": " • May 8, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Waves of COVID-19 infections across the world",
            "content": "Waves of infection across the world over time . Throughout the COVID-19 pandemic the headlines have often focused on record daily figures for individual countries. We lose an overview of how various countries are doing over time. . As part of the TrueCue Women in Data Hackathon, team AMIA decided to explore the data by preparing an animated gif of the world with daily plots. Since the disease affects people not land, it made sense to use a cartogram where each cell represented a number of people. This style of graphic looks strange but makes a lot of sense for a pandemic, which affects people not land area. As a contrast, the same data is shown on a world map, using the Equal Earth projection, to see the different impression that is given. . The aim of this notebook is to show how to put together these .gifs using open source components, both data and software. The same basic structure can be used to show any data that you have at a country level. . The data shown are 14-day notification rates for COVID-19, a metric widely used to get an idea of how countries are managing. Although each country has its own criteria for testing for the disease and notifying cases this data gives an indication of how countries are coping. . Library imports to run the notebook on Google Colab: . !pip install geopandas !apt install gifsicle !pip install pygifsicle import pandas as pd import geopandas as gpd import matplotlib.pyplot as plt from matplotlib.collections import PatchCollection from matplotlib.lines import Line2D from matplotlib.patches import Rectangle from PIL import Image import requests from io import BytesIO from pathlib import * from pygifsicle import optimize path=Path() for dir_out in [&#39;pngs_world&#39;, &#39;pngs_world_map&#39;]: dest = (path/dir_out) dest.mkdir(exist_ok=True) . . World cartogram . . Image.open(&#39;./pngs_world/2020-11-20.png&#39;) . Original cartogram from Max Roser of &#39;Our World in Data&#39; . Image.open(BytesIO(requests.get(&#39;https://upload.wikimedia.org/wikipedia/commons/9/90/Global_population_cartogram.png&#39;).content)) . . A while ago I made a cartogram that maps where the world population lives.Now @mattdzugan just emailed me and showed me a new version of that cartogram – with it he enables everyone to make a map like this.You can use it in R, Python, d3 etc.→ https://t.co/nVeWaQKD4t pic.twitter.com/IGjOiCCVXU . &mdash; Max Roser (@MaxCRoser) October 12, 2020 . World map . . Image.open(&#39;./pngs_world_map/2020-11-20.png&#39;) . The most striking differences between the cartogram and the map . the map under represents the population of India | the map over represents the population of Canada and Russia. | . The .gifs generated by this notebook have been converted to .mp4 video online and uploaded to youtube. . Import the latest COVID-19 data from &#39;Our World in Data&#39; . df=(pd.read_csv(&#39;https://covid.ourworldindata.org/data/owid-covid-data.csv&#39;))[[&#39;date&#39;,&#39;new_cases&#39;,&#39;iso_code&#39;,&#39;population&#39;]] df.head().T . 0 1 2 3 4 . date 2019-12-31 | 2020-01-01 | 2020-01-02 | 2020-01-03 | 2020-01-04 | . new_cases 0 | 0 | 0 | 0 | 0 | . iso_code AFG | AFG | AFG | AFG | AFG | . population 3.89283e+07 | 3.89283e+07 | 3.89283e+07 | 3.89283e+07 | 3.89283e+07 | . Extract daily new_cases: new confirmed cases of COVID-19 for 215 countries . df_pvt=df.pivot(index=&#39;date&#39;, columns=&#39;iso_code&#39;, values=&#39;new_cases&#39;).fillna(0).astype(&#39;int&#39;) df_pvt.drop(df_pvt.columns[0], axis=1, inplace=True) df_pvt.head().T . date 2019-12-31 2020-01-01 2020-01-02 2020-01-03 2020-01-04 . iso_code . ABW 0 | 0 | 0 | 0 | 0 | . AFG 0 | 0 | 0 | 0 | 0 | . AGO 0 | 0 | 0 | 0 | 0 | . AIA 0 | 0 | 0 | 0 | 0 | . ALB 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | . WLF 0 | 0 | 0 | 0 | 0 | . YEM 0 | 0 | 0 | 0 | 0 | . ZAF 0 | 0 | 0 | 0 | 0 | . ZMB 0 | 0 | 0 | 0 | 0 | . ZWE 0 | 0 | 0 | 0 | 0 | . 215 rows × 5 columns . Calculate the 14-day notification rate per 100_000 population for each country . df_14_day=pd.DataFrame() for col in df_pvt.columns: df_14_day[col]=df_pvt[col].rolling(window=14).sum() df_14_day.fillna(0, inplace=True) for col in df_14_day.columns[1:]: popn=(df.loc[(df.date==&#39;2020-11-01&#39;) &amp; (df.iso_code==col), &#39;population&#39;]/100000).values if len(popn) &gt; 0: # avoid dividing by 0 df_14_day[col]=df_14_day[col]/popn else: print (&#39;No population data for&#39;, col) df_14_day = df_14_day.T df_14_day.head().T . No population data for VUT . ABW AFG AGO AIA ALB . date . 2019-12-31 0.0 | 0.000000 | 0.000000 | 0.0 | 0.000000 | . 2020-01-01 0.0 | 0.000000 | 0.000000 | 0.0 | 0.000000 | . 2020-01-02 0.0 | 0.000000 | 0.000000 | 0.0 | 0.000000 | . 2020-01-03 0.0 | 0.000000 | 0.000000 | 0.0 | 0.000000 | . 2020-01-04 0.0 | 0.000000 | 0.000000 | 0.0 | 0.000000 | . ... ... | ... | ... | ... | ... | . 2020-11-16 143.0 | 4.546816 | 7.816525 | 0.0 | 230.314824 | . 2020-11-17 144.0 | 4.469751 | 7.351002 | 0.0 | 240.079227 | . 2020-11-18 138.0 | 5.232692 | 7.262766 | 0.0 | 250.955591 | . 2020-11-19 132.0 | 4.921864 | 6.818541 | 0.0 | 261.901452 | . 2020-11-20 129.0 | 5.543519 | 6.416914 | 0.0 | 274.584752 | . 326 rows × 5 columns . Sanity check - look at rates for the last week for some example countries . df_14_day.loc[[&#39;ESP&#39;,&#39;GBR&#39;,&#39;USA&#39;,&#39;FRA&#39;,&#39;DEU&#39;]].T.tail(7) . ESP GBR USA FRA DEU . date . 2020-11-14 583.711403 | 482.796130 | 511.230655 | 904.685502 | 304.119124 | . 2020-11-15 583.711403 | 490.080400 | 537.315945 | 903.849022 | 307.425247 | . 2020-11-16 547.894747 | 492.596383 | 552.774734 | 870.049707 | 305.905863 | . 2020-11-17 536.109856 | 496.150871 | 578.315919 | 804.001476 | 304.792284 | . 2020-11-18 515.311984 | 496.199482 | 596.920604 | 818.083758 | 305.206445 | . 2020-11-19 503.174189 | 487.997497 | 617.312586 | 799.431475 | 308.332342 | . 2020-11-20 455.016549 | 486.195947 | 637.126325 | 742.906250 | 310.888918 | . Specify colour scales, country codes, cartogram cells, legend cells and country boundaries . To prepare the plots we need to specify some basics: . the colour scales up to 120 are based on the European Centre for Disease Prevention and Control levels for worldwide maps; for higher rates they are then doubled. | the numeric country codes are used for the cartogram cells and the three character codes are used by &#39;Our World in Data&#39;. A look-up table is needed to match the codes. All codes come from the international standard ISO-3166. | cell and boundaries were created by Matt Dzugan for a World Population Cartogram, where each cell represents a population of 500 000 people in its corresponding country. | the country boundaries for the world map are from Eurostat © EuroGeographics for the administrative boundaries. | . cut_labels=[&#39;&lt;20&#39;,&#39;20-59.9&#39;,&#39;60-119.9&#39;,&#39;120-239.9&#39;,&#39;240-479.9&#39;,&#39;480-959.9&#39;,&#39;&gt;960&#39;] cut_bins = [-1, 20., 60., 120., 240., 480., 960., 2000.] color_dict={&#39;&lt;20&#39;:&#39;lemonchiffon&#39;,&#39;20-59.9&#39;:&#39;yellow&#39;,&#39;60-119.9&#39;:&#39;orange&#39;,&#39;120-239.9&#39;:&#39;chocolate&#39;,&#39;240-479.9&#39;:&#39;brown&#39;,&#39;480-959.9&#39;:&#39;red&#39;, &#39;&gt;960&#39;:&#39;black&#39;} # ISO 3166 country codes iso_3166=pd.read_csv(&#39;https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/slim-3/slim-3.csv&#39;, dtype={&#39;name&#39;:&#39;str&#39;,&#39;alpha-3&#39;:&#39;str&#39;,&#39;country-code&#39;:&#39;float64&#39;}) # world population cartogram cells and borders cells = pd.read_csv(&quot;https://raw.githubusercontent.com/mattdzugan/World-Population-Cartogram/master/data/year_2018__cell_500k/squares_and_triangles/cells.csv&quot;) borders = pd.read_csv(&quot;https://raw.githubusercontent.com/mattdzugan/World-Population-Cartogram/master/data/year_2018__cell_500k/squares_and_triangles/borders.csv&quot;) # country boundaries previously downloaded from Eurostat shapefile = path/&#39;CNTR_RG_60M_2020_4326.shp/CNTR_RG_60M_2020_4326.shp&#39; gdf = gpd.read_file(shapefile).to_crs(&quot;EPSG:8857&quot;) # legend cells sq1 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;lemonchiffon&quot;) sq2 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;yellow&quot;) sq3 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;orange&quot;) sq4 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;chocolate&quot;) sq5 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;brown&quot;) sq6 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;red&quot;) sq7 = Line2D([0], [0], linestyle=&quot;none&quot;, marker=&quot;s&quot;, alpha=0.7, markersize=8, markerfacecolor=&quot;black&quot;) . The world map uses the Equal Earth map projection, which is an equal-area pseudocylindrical projection, invented by Bojan Šavrič, Bernhard Jenny, and Tom Patterson in 2018. It is inspired by the widely used Robinson projection but retains the relative size of areas. . gdf.crs # coordinate reference system . &lt;Projected CRS: EPSG:8857&gt; Name: WGS 84 / Equal Earth Greenwich Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - name: World. - bounds: (-180.0, -90.0, 180.0, 90.0) Coordinate Operation: - name: Equal Earth Greenwich - method: Equal Earth Datum: World Geodetic System 1984 - Ellipsoid: WGS 84 - Prime Meridian: Greenwich . Generate a plot for each day . Convert the data frame of 14-day infection rates to colours and add country codes. . for col in df_14_day: df_14_day[col] = pd.cut(df_14_day[col], bins=cut_bins, labels=cut_labels).map(color_dict) df_14_day = df_14_day.merge(iso_3166, left_index=True, right_on=&#39;alpha-3&#39;) . Make and save a plot for each day, show the plots for the start and end dates . cartogram = True # toggle between cartogram and world map start_date = &#39;2020-05-01&#39; end_date = df_14_day.columns[-4] cols_lst = [-i-4 for i in range((pd.to_datetime(end_date)-pd.to_datetime(start_date)).days+1)][::-1] for date in df_14_day.columns[cols_lst]: print_date = date[-2:]+date[-6:-3]+&#39;-&#39;+date[:4] if cartogram: cells_day = cells.merge(df_14_day[[date, &#39;country-code&#39;]], left_on=&#39;CountryCode&#39;, right_on=&#39;country-code&#39;, how=&#39;left&#39;) cells_day[date].fillna(&#39;lemonchiffon&#39;, inplace=True) fig = plt.figure(figsize=(16,9)) ax = fig.add_subplot(111, aspect=&#39;equal&#39;) plt.xlim([0, max(cells_day.X+1)]) plt.ylim([0, max(cells_day.Y+1)]) patches = [(Rectangle((cells_day.loc[i,&#39;X&#39;]+.5, cells_day.loc[i,&#39;Y&#39;]+.5), 1, 1)) for i in range(cells_day.shape[0])] ax.add_collection(PatchCollection(patches, color=cells_day[date], alpha=0.7)) for p in borders.PolygonID.unique(): ax.plot(borders.loc[borders.PolygonID==p, &#39;X&#39;]+.5, borders.loc[borders.PolygonID==p, &#39;Y&#39;]+.5, color=&#39;grey&#39;, lw=.5) legend_title=&#39;1 cell: 500 000 people n nRate&#39; footer=&quot;Data sources: &#39;Our World in Data&#39; and https://github.com/mattdzugan/World-Population-Cartogram nAuthor: @data_sigh&quot; else: # world map merged = gdf.merge(df_14_day[[date, &#39;alpha-3&#39;]], left_on=&#39;ISO3_CODE&#39;, right_on=&#39;alpha-3&#39;, how=&#39;left&#39;) merged.drop(merged[merged[&#39;ISO3_CODE&#39;]==&#39;ATA&#39;].index, inplace=True) # drop Antartica merged.fillna(&#39;lemonchiffon&#39;,inplace=True) # fill NaN such as Kashmir with lowest rate ax = merged.plot(color=merged[date], figsize=(16,9), legend=True, edgecolor=&#39;grey&#39;, lw=.3) legend_title=&#39;Rate&#39; footer = &quot;Data sources: &#39;Our World in Data&#39; and © EuroGeographics for the administrative boundaries nAuthor: @data_sigh&quot; plt.legend((sq1, sq2, sq3, sq4, sq5, sq6, sq7), cut_labels, numpoints=1, loc=(.0,.75), title=legend_title, fontsize=10, frameon=False) title = &#39;14-day COVID-19 case notification rate per 100 000 population n&#39; + print_date plt.title(title, fontsize=14) plt.axis(&#39;off&#39;) plt.figtext(0.5, 0.11, footer, ha=&#39;center&#39;, fontsize=12) plt.tight_layout() if cartogram: plt.savefig(path/&#39;pngs_world&#39;/date, dpi=150) else: plt.savefig(path/&#39;pngs_world_map&#39;/date, dpi=150) if date == start_date or date == end_date: plt.show() plt.close() . Write the plots to a .gif . if cartogram: png_dir = path/&#39;pngs_world&#39; gif_name = &#39;world.gif&#39; else: png_dir = path/&#39;pngs_world_map&#39; gif_name = &#39;world_map.gif&#39; images = [Image.open(png_dir/img.name) for img in sorted(list(Path.glob(png_dir, pattern=&#39;*.png&#39;))) if (img.name&gt;=start_date+&#39;.png&#39;) &amp; (img.name&lt;=end_date+&#39;.png&#39;)] images[0].save(fp=gif_name, format=&#39;GIF&#39;, append_images=images[1:], save_all=True, duration=100, loop=1) optimize(gif_name) # make the gif file size smaller using pygifsicle . Thanks to the TrueCue Women in Data Hackathon . Thanks to TrueCue for organising the hackathon and encouraging us all to produce a data analysis. They did a wonderful job managing the hackathon and getting everybody involved. Huge congratulations to the winning teams: Google Gals, MACS and Fishing Consultancy. . All participants got a certificate. I&#39;ll show you mine. . Image.open(&#39;TrueCue_Women_in_Data_Hackathon_Certificate.jpg&#39;) . . Stay safe! . Advice from the World Health Organisation . Avoid the 3Cs: spaces that are closed, crowded or involve close contact. Outbreaks have been reported in restaurants, choir practices, fitness classes, nightclubs, offices and places of worship where people have gathered, often in crowded indoor settings where they talk loudly, shout, breathe heavily or sing. The risks of getting COVID-19 are higher in crowded and inadequately ventilated spaces where infected people spend long periods of time together in close proximity. These environments are where the virus appears to spread by respiratory droplets or aerosols more efficiently, so taking precautions is even more important. | Meet people outside. Outdoor gatherings are safer than indoor ones, particularly if indoor spaces are small and without outdoor air coming in. Avoid crowded or indoor settings but if you can’t, then take precautions: Open a window. Increase the amount of ‘natural ventilation’ when indoors. | Wear a mask | .",
            "url": "https://alisondavey.github.io/fastpages/covid19/cartogram/geopandas/equalearth/2020/11/20/world_cartogram_latest_OWID.html",
            "relUrl": "/covid19/cartogram/geopandas/equalearth/2020/11/20/world_cartogram_latest_OWID.html",
            "date": " • Nov 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "The good data in Madrid continues",
            "content": "import pandas as pd import re import matplotlib.pyplot as plt import plotnine from plotnine import * import warnings warnings.filterwarnings(&#39;ignore&#39;) . . On 3rd October 2020, the official account of the regional authority of Madrid put out a series of tweets under the ending The good data in Madrid continues. Here we will attempt to reproduce the first graphic and statistics and reflect if this communicates an appropriate message. . This has also been covered by El Diario ¿Está Madrid realmente doblegando la curva? Los datos que no muestran los tuits triunfalistas de Ayuso 📉 Continúan los buenos datos en la Comunidad de Madrid. Entre todos, derrotaremos al virus. ¡Vamos! 💪 pic.twitter.com/2xfkHELFsG . &mdash; Comunidad de Madrid (@ComunidadMadrid) October 3, 2020 . &#39;La evolución de los casos diagnosticados durante la semana de 21 al 27 de septiembre es un 25% inferior a los de la semana del 14 al 20 de septiembre.&#39; . &#39;The evolution of the cases diagnosed during the week of September 21 to 27 is 25% lower than those of the week of September 14 to 20.&#39; . The graph includes the annotation of -24.6%. The first challenge is to generate this statistic. . def find_statistic(date,a,b): return print(&#39;report {}, total week 1: {}, total week 2: {}, % change: {}&#39;.format(date,sum(a),sum(b),100*(-1+sum(b)/sum(a)))) . find_statistic(&#39;El Diario&#39;, [26781], [20206]) . report El Diario, total week 1: 26781, total week 2: 20206, % change: -24.550987640491396 . Daily reports from the regional health authority . From the daily report from the regional authority for 2 October 2020, the cases diagnosed for these two weeks were . sept_14_20=[2148,5562,5101,4965,6658,1615,1011] sept_21_27=[1956,4617,4206,3852,4508,1194,770] find_statistic(&#39;2 Oct&#39;,sept_14_20,sept_21_27) . report 2 Oct, total week 1: 27060, total week 2: 21103, % change: -22.0140428677014 . Let&#39;s have a look at earlier reports and see if we can get closer to -24.6%. . sept_14_20=[2145,5550,5089,4934,6643,1608,1008] sept_21_27=[1949,4600,4190,3834,4461,1188,768] find_statistic(&#39;1 Oct&#39;,sept_14_20,sept_21_27) . report 1 Oct, total week 1: 26977, total week 2: 20990, % change: -22.192979204507544 . sept_14_20=[2139,5550,5072,4917,6633,1601,1001] sept_21_27=[1941,4580,4152,3818,4325,1109,743] find_statistic(&#39;30 Sept&#39;,sept_14_20,sept_21_27) . report 30 Sept, total week 1: 26913, total week 2: 20668, % change: -23.20439936090365 . sept_14_20=[2133,5460,5057,4897,6605,1591,996] sept_21_27=[1932,4550,4100,3727,3741,980,694] find_statistic(&#39;29 Sept&#39;,sept_14_20,sept_21_27) . report 29 Sept, total week 1: 26739, total week 2: 19724, % change: -26.235087325629237 . sept_14_20=[2129,5448,5046,4885,6583,1584,984] sept_21_27=[1906,4498,3844,3236,3078,769,457] find_statistic(&#39;28 Sept&#39;,sept_14_20,sept_21_27) . report 28 Sept, total week 1: 26659, total week 2: 17788, % change: -33.27581679732923 . The variation in the percentage change is due to the series for the daily figures changing as the information is backfilled. The daily reports of cases confirmed by PCR are updated as new cases are notified. They are allocated to the date on which the test was taken. . Casos positivos de Covid-19 confirmados por PCR . La Comunidad de Madrid consolida diariamente la serie de casos confirmados por PCR, asignando a los casos nuevos notificados la fecha en la que se toma la muestra. Se realiza una actualización diaria de la serie de casos que se adjunta. . Looking at the latest date: . sept_14_20=[2161,5591,5123,4963,6696,1622,1027] sept_21_27=[1985,4659,4248,3880,4572,1219,791] find_statistic(&#39;6 Oct&#39;,sept_14_20,sept_21_27) . report 6 Oct, total week 1: 27183, total week 2: 21354, % change: -21.443549277121733 . Based on the regional authorities latest daily figures the % change between the two weeks is -21.4%. Falling from 27_183 positive PCRs to 21_354 positive PCRs in a week. . plt.scatter([&#39;28-09&#39;,&#39;29-09&#39;,&#39;30-09&#39;,&#39;01-10&#39;,&#39;02-10&#39;,&#39;05-10&#39;],[-33.28,-26.24,-23.20,-22.19,-22.01,-21.54,]) plt.xlabel(&#39;date of report&#39;) plt.ylabel(&#39;% change total week on week&#39;) plt.ylim(-35,-20) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.title(&#39;Compare week 14-20 Sept. to 21-27 Sept.&#39;); . . Weekly reports from the regional health authority . Table 1 of the weekly epidemiological report for week 39 (provisional data) contains data similar to that shown in the tweet. . Week 36 Week 37 Week 38 Week 39 . Dates | 31-08 - 06-09 | 07-09 - 13-09 | 14-09 - 20-09 | 21-09 - 27-09 | . Total | 19665 | 24402 | 28685 | 21981 | . Change | | 1,24 | 1,18 | 0,77 | . find_statistic(&#39;Weekly epidemiological&#39;,[28685],[21981]) # https://www.comunidad.madrid/sites/default/files/doc/sanidad/epid/informe_epidemiologico_semanal_covid.pdf # Week 39 provisional data . report Weekly epidemiological, total week 1: 28685, total week 2: 21981, % change: -23.371099877985014 . Let&#39;s look at the weekly data provided by the regional authority for municipalities and districts. . munis_df=pd.read_csv(&#39;./fastpages/covid19_tia_muni_y_distritos_s.csv&#39;, delimiter=&#39;;&#39;, encoding=&#39;latin&#39;) munis_df.fecha_informe=munis_df.fecha_informe.apply(lambda x: x[5:10]) munis_df.casos_confirmados_totales=munis_df.casos_confirmados_totales.fillna(0).astype(&#39;int&#39;) munis_df[[&#39;municipio_distrito&#39;,&#39;fecha_informe&#39;,&#39;casos_confirmados_totales&#39;]].head() . municipio_distrito fecha_informe casos_confirmados_totales . 0 Madrid-Retiro | 09/29 | 3940 | . 1 Madrid-Salamanca | 09/29 | 4770 | . 2 Madrid-Centro | 09/29 | 4820 | . 3 Madrid-Arganzuela | 09/29 | 5293 | . 4 Madrid-Chamartín | 09/29 | 4543 | . df_casos=munis_df[[&#39;municipio_distrito&#39;,&#39;fecha_informe&#39;,&#39;casos_confirmados_totales&#39;]].pivot(index=&#39;municipio_distrito&#39;, columns=&#39;fecha_informe&#39;, values=&#39;casos_confirmados_totales&#39;) df_casos=df_casos.fillna(0).astype(&#39;int&#39;) df_casos.sort_values(&#39;09/29&#39;, ascending=False).head(5) . fecha_informe 05/26 06/02 06/09 06/16 06/23 06/30 07/07 07/14 07/21 07/28 08/04 08/11 08/18 08/25 09/01 09/08 09/15 09/22 09/29 . municipio_distrito . Madrid-Puente de Vallecas 3150 | 3199 | 3242 | 3279 | 3328 | 3344 | 3382 | 3424 | 3454 | 3523 | 3668 | 3997 | 4847 | 6190 | 7575 | 9033 | 10834 | 12628 | 14397 | . Madrid-Carabanchel 2798 | 2848 | 2883 | 2910 | 2943 | 2959 | 2991 | 3039 | 3073 | 3124 | 3293 | 3689 | 4442 | 5272 | 6289 | 7570 | 8840 | 10356 | 11656 | . Madrid-Ciudad Lineal 2315 | 2339 | 2373 | 2394 | 2406 | 2436 | 2480 | 2514 | 2542 | 2573 | 2663 | 2871 | 3233 | 3813 | 4559 | 5345 | 6569 | 7702 | 8527 | . Madrid-Latina 2890 | 2946 | 2982 | 3018 | 3055 | 3086 | 3104 | 3129 | 3166 | 3233 | 3344 | 3585 | 3995 | 4351 | 4777 | 5572 | 6189 | 7300 | 8202 | . Fuenlabrada 1626 | 1645 | 1659 | 1682 | 1699 | 1716 | 1733 | 1744 | 1783 | 1841 | 1957 | 2171 | 2663 | 3168 | 3960 | 4580 | 5608 | 6651 | 7703 | . find_statistic(&#39;weekly_report&#39;, [sum(df_casos.iloc[:,-2]-df_casos.iloc[:,-3])],[sum(df_casos.iloc[:,-1]-df_casos.iloc[:,-2])]) . report weekly_report, total week 1: 29316, total week 2: 28164, % change: -3.9295947605403225 . weekly_new_cases=[sum(df_casos.iloc[:,-i]-df_casos.iloc[:,(-i-1)]) for i in range(1,11)][::-1]; weekly_new_cases . [1311, 2835, 5586, 10549, 14681, 17299, 20086, 24374, 29316, 28164] . weekly_pct_change=[100*(-1+weekly_new_cases[i+1]/weekly_new_cases[i]) for i in range(1,len(weekly_new_cases)-1)];weekly_pct_change . [97.03703703703704, 88.84711779448622, 39.169589534553026, 17.832572713030448, 16.110757847274403, 21.34820272826845, 20.275703618609995, -3.9295947605403225] . It&#39;s not clear to me why working with the weekly municipality data there is only a 4% fall in the last week in the number of cases, far from the 25% we are looking for. . fig, ax = plt.subplots(1,1,figsize=(10,6)) plt.bar(df_casos.columns[-10:],weekly_new_cases) plt.ylabel(&#39;cases&#39;) plt.xlabel(&#39;date&#39;) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.title(&#39;cases added in previous week nbased on report of 29/09/2020&#39;); . . fig, ax = plt.subplots(1,1,figsize=(12,6)) plt.plot(df_casos.columns[-8:],weekly_pct_change[-8:]) plt.ylim(-40,100) plt.grid(b=True, which=&#39;major&#39;, axis=&#39;y&#39;) plt.xlabel(&#39;date&#39;) plt.ylabel(&#39;% change&#39;) plt.title(&#39;change in number of new cases added weekly&#39;); . . More on the daily reports from the regional health authority . daily_df=pd.read_excel(&#39;./fastpages/CAM_casos_diarios.xlsx&#39;, skipfooter=18).rename(columns={&#39;Unnamed: 0&#39;:&#39;fecha&#39;}) daily_df.cumul_casos_201006.tail() # Excel created by hand from the daily pdf reports . 80 257145.0 81 257849.0 82 258102.0 83 259322.0 84 NaN Name: cumul_casos_201006, dtype: float64 . fig, ax = plt.subplots(1,1,figsize=(10,6)) plt.bar(daily_df.fecha[:-1],daily_df.casos_201006[:-1]) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.title(&#39;cases added daily&#39;); . daily_df.fecha=daily_df.fecha.apply(lambda x: str(x)[5:10]) weekly_df=daily_df.iloc[::7] weekly_df.loc[:,&#39;cases_added&#39;]=weekly_df.cumul_casos_201006.diff().fillna(0).astype(&#39;int&#39;) weekly_df[&#39;percent_change&#39;]=100*weekly_df.cases_added.pct_change() weekly_df.loc[weekly_df.index[:2],&#39;percent_change&#39;]=0 weekly_df[[&#39;fecha&#39;,&#39;percent_change&#39;]] . fecha percent_change . 0 07-14 | 0.000000 | . 7 07-21 | 0.000000 | . 14 07-28 | 66.260658 | . 21 08-04 | 88.095238 | . 28 08-11 | 64.323272 | . 35 08-18 | 56.399621 | . 42 08-25 | 31.090399 | . 49 09-01 | 3.849711 | . 56 09-08 | 13.163754 | . 63 09-15 | 25.689833 | . 70 09-22 | 2.038820 | . 77 09-29 | -23.604986 | . 84 10-06 | -100.000000 | . fig, ax = plt.subplots(1,1,figsize=(10,6)) plt.bar(weekly_df.fecha[1:-1],weekly_df.cases_added[1:-1]) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.xlabel(&#39;date&#39;) plt.ylabel(&#39;new cases&#39;) plt.title(&#39;cases added weekly&#39;); . . fig, ax = plt.subplots(1,1,figsize=(12,6)) plt.plot(weekly_df.fecha[2:-1],weekly_df.percent_change[2:-1]) plt.ylim(-40,100) plt.grid(b=True, which=&#39;major&#39;, axis=&#39;y&#39;) plt.xlabel(&#39;date&#39;) plt.ylabel(&#39;% change&#39;) plt.title(&#39;change in number of new cases added weekly&#39;); . . Using the daily reports we get close to reproducing the graphic tweeted out. This graphic shows the percentage change between the total number of new cases in one week compared to the previous week. It is a measure of change but in this context is very misleading. . A simple bar chart shows not only the change in the number of cases but also the magnitude of the problem. If cases double in a week from 100 to 200 the change is 100% but you have some possibility of tracing the contacts of 200 people. Once you have 25_000 new cases in a week, even if there are &#39;only&#39; 25_000 new cases the following week (so 0% change) you have a major problem. . Hospital data since September . With the number of new daily cases there should be a fall in the number of people hospitalized, although with a time lag. Is this already a pattern? . fig, ax = plt.subplots(1,1,figsize=(10,6)) plt.scatter(daily_df.fecha, daily_df.uci) plt.xlabel(&#39;date&#39;) plt.ylabel(&#39;number of people in intensive care&#39;) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.xticks(rotation=270) plt.ylim(0,600) plt.title(&#39;People in Intensive Care&#39;); . . fig, ax = plt.subplots(1,1,figsize=(10,6)) plt.scatter(daily_df.fecha, daily_df.hospitalizados) plt.xlabel(&#39;date&#39;) # get rid of the frame for spine in plt.gca().spines.values(): spine.set_visible(False) plt.xticks(rotation=270) plt.ylim(0,3500) plt.ylabel(&#39;number of people in hospital&#39;) plt.title(&#39;People in Hospital&#39;); . . Going in the right direction! .",
            "url": "https://alisondavey.github.io/fastpages/madrid/covid19/disinformation/2020/10/06/disinformation.html",
            "relUrl": "/madrid/covid19/disinformation/2020/10/06/disinformation.html",
            "date": " • Oct 6, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Restrictions in the Madrid region for nearly 5 million people",
            "content": "!pip install geopandas import geopandas import pandas as pd import re import matplotlib.pyplot as plt import plotnine from plotnine import * . . Focus on Municipalities . For the latest round of restrictions due to Covid19 in the Madrid region the focus has switched from basic health areas to municipalities. . This notebook explores the municipalities of the region and the current rates of infection. . The Madrid region has 179 municipalities with population ranging from 48 people in Madarcos to 3.3 million people in Madrid capital (based on the 2019 population register). There are 10 municipalities with more than 100_000 inhabitants: Madrid, Móstoles, Alcalá de Henares, Fuenlabrada, Leganés, Getafe, Alcorcón, Torrejón de Ardoz, Parla, Alcobendas. . The regional authority provides weekly figures for Covid19 infections for 178 municipalities and the 21 districts of Madrid capital. . The health ministry has imposed new restrictions on municipalities with a population of over 100_000 that have an accumulated incidence rate for the last 14 days of over 500 per 100_000 inhabitants (and meet additional criteria). . The 10 municipalities in the Madrid region with a population of over 100_000 had a rate of between 525 (Alcalá de Henares) and 1_166 (Fuenlabrada) at 29 September 2020. Madrid capital had a rate of 776. . 72% of the population of the Madrid region live in these municipalities. . These municipalities now have Covid19 restrictions based on the criteria of the health ministry. . At the same date, there are an additional 19 municipalities with rates over 1_000, with a total population of 67_300: Humanes de Madrid, Cobeña, Villa del Prado, Cubas de la Sagra, Moraleja de Enmedio, Torrelaguna, Casarrubuelos, Villaconejos, Navalagamella, Fuentidueña de Tajo, Villar del Olmo, Orusco de Tajuña, El Berrueco, Rozas de Puerto Real, Canencia, Braojos, Cervera de Buitrago. El Atazar, Puebla de la Sierra. . The regional authority has imposed restrictions on 3 basic health areas outside of the 10 large municipalities that have restrictions: Humanes de Madrid, Reyes Católicos, Villa del Prado. . Read and prepare the data . df=pd.read_excel(&#39;./maps/Municipios/20codmun28.xls&#39;, header=2) # source https://www.ine.es/daco/daco42/codmun/codmunmapa.htm df.head() . CPRO CMUN DC NOMBRE . 0 28 | 1 | 4 | Acebeda, La | . 1 28 | 2 | 9 | Ajalvir | . 2 28 | 3 | 5 | Alameda del Valle | . 3 28 | 4 | 0 | Álamo, El | . 4 28 | 5 | 3 | Alcalá de Henares | . munis_df=pd.read_csv(&#39;./fastpages/covid19_tia_muni_y_distritos_s.csv&#39;, delimiter=&#39;;&#39;, encoding=&#39;latin&#39;) # source http://datos.comunidad.madrid/catalogo/dataset/covid19_tia_muni_y_distritos for col in [&#39;tasa_incidencia_acumulada_activos_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_total&#39;]: munis_df[col] = pd.to_numeric(munis_df[col].apply(lambda x: re.sub(&#39;,&#39;, &#39;.&#39;, x))) munis_df.rename(columns={&#39;tasa_incidencia_acumulada_ultimos_14dias&#39;:&#39;tasa&#39;, &#39;casos_confirmados_ultimos_14dias&#39;:&#39;casos&#39;, &#39;codigo_geometria&#39;:&#39;codigo_geo&#39;}, inplace=True) munis_df.fecha_informe=munis_df.fecha_informe.apply(lambda x: x[5:10]) munis_df.casos_confirmados_activos_ultimos_14dias=munis_df.casos_confirmados_activos_ultimos_14dias.fillna(0).astype(&#39;int&#39;) munis_df.casos=munis_df.casos.fillna(0).astype(&#39;int&#39;) munis_df.casos_confirmados_totales=munis_df.casos_confirmados_totales.fillna(0).astype(&#39;int&#39;) munis_df.codigo_geo=munis_df.codigo_geo.fillna(0).astype(&#39;int&#39;) munis_df.head() . municipio_distrito fecha_informe casos_confirmados_activos_ultimos_14dias tasa_incidencia_acumulada_activos_ultimos_14dias casos tasa casos_confirmados_totales tasa_incidencia_acumulada_total codigo_geo . 0 Madrid-Retiro | 09/29 | 253 | 212.04 | 745 | 624.39 | 3940 | 3302.13 | 79603 | . 1 Madrid-Salamanca | 09/29 | 404 | 276.52 | 1120 | 766.58 | 4770 | 3264.80 | 79604 | . 2 Madrid-Centro | 09/29 | 347 | 257.33 | 1016 | 753.44 | 4820 | 3574.39 | 79601 | . 3 Madrid-Arganzuela | 09/29 | 310 | 201.56 | 1051 | 683.34 | 5293 | 3441.42 | 79602 | . 4 Madrid-Chamartín | 09/29 | 259 | 177.58 | 915 | 627.36 | 4543 | 3114.87 | 79605 | . gdf=geopandas.read_file(&#39;./maps/Municipios/municipios_y_distritos_madrid.shp&#39;) # source http://datos.comunidad.madrid/catalogo/dataset/covid19_tia_muni_y_distritos . gdf[gdf.pob_pad19==gdf.pob_pad19.min()] # municipality with smallest population . codigo_geo pob_pad19 municipio_ geometry . 123 0783 | 48 | Madarcos | POLYGON ((451455.976 4545468.339, 451953.119 4... | . print(gdf.loc[:20,].pob_pad19.sum(), &#39;population Madrid capital&#39;) . 3266126 population Madrid capital . print (len(gdf),&#39; municipalities/districts&#39;) . 199 municipalities/districts . gdf.loc[21:,][gdf.loc[21:,].pob_pad19&gt;100000].sort_values(&#39;pob_pad19&#39;,ascending=False)[[&#39;municipio_&#39;,&#39;pob_pad19&#39;]] # 9 other municipalities with a population over 100 000 . municipio_ pob_pad19 . 79 Móstoles | 209184 | . 178 Alcalá de Henares | 195649 | . 59 Fuenlabrada | 193700 | . 80 Leganés | 189861 | . 195 Getafe | 183374 | . 22 Alcorcón | 170514 | . 184 Torrejón de Ardoz | 131376 | . 86 Parla | 130124 | . 177 Alcobendas | 117040 | . gdf.loc[:20].sort_values(&#39;pob_pad19&#39;,ascending=False)[[&#39;municipio_&#39;,&#39;pob_pad19&#39;]] # population of the 21 districts of Madrid . municipio_ pob_pad19 . 10 Madrid-Carabanchel | 253099 | . 7 Madrid-Fuencarral-El Pardo | 245939 | . 9 Madrid-Latina | 238218 | . 12 Madrid-Puente de Vallecas | 234857 | . 16 Madrid-Ciudad Lineal | 216284 | . 17 Madrid-Hortaleza | 188187 | . 13 Madrid-San Blas - Canillejas | 158142 | . 5 Madrid-Tetuán | 158023 | . 3 Madrid-Arganzuela | 153803 | . 18 Madrid-Villaverde | 148946 | . 1 Madrid-Salamanca | 146104 | . 4 Madrid-Chamartín | 145849 | . 11 Madrid-Usera | 139741 | . 6 Madrid-Chamberí | 139379 | . 2 Madrid-Centro | 134848 | . 8 Madrid-Moncloa-Aravaca | 119419 | . 0 Madrid-Retiro | 119317 | . 19 Madrid-Villa de Vallecas | 110365 | . 15 Madrid-Moratalaz | 94570 | . 20 Madrid-Vicálvaro | 72091 | . 14 Madrid-Barajas | 48945 | . munis_df.tasa.fillna(0, inplace=True) # allocate to bins of accumulated incidence rate for the last 14 days cut_labels=[&#39;&lt;200&#39;,&#39;200-400&#39;,&#39;400-600&#39;,&#39;600-800&#39;,&#39;800-1000&#39;,&#39;&gt;1000&#39;] cut_bins = [-1., 200., 400., 600., 800., 1000., max(munis_df.tasa)] munis_df[&#39;tasa_bin&#39;] = pd.cut(munis_df.tasa, bins=cut_bins, labels=cut_labels) gdf[&#39;restricted&#39;]=&#39;0&#39; gdf.loc[:20,&#39;restricted&#39;]=&#39;1&#39; gdf.loc[gdf.pob_pad19&gt;100000,&#39;restricted&#39;]=&#39;1&#39; # all districts in Madrid capital restricted munis_df[&#39;restricted&#39;]=&#39;0&#39; munis_df.loc[gdf[gdf.restricted==&#39;1&#39;].index,&#39;restricted&#39;]=&#39;1&#39; for muni in gdf[gdf.restricted==&#39;1&#39;].municipio_: munis_df.loc[munis_df.municipio_distrito==muni, &#39;restricted&#39;]=&#39;1&#39; gdf.head() . codigo_geo pob_pad19 municipio_ geometry restricted . 0 079603 | 119317 | Madrid-Retiro | POLYGON ((443663.017 4473349.384, 443663.267 4... | 1 | . 1 079604 | 146104 | Madrid-Salamanca | POLYGON ((444067.804 4476571.218, 444057.220 4... | 1 | . 2 079601 | 134848 | Madrid-Centro | POLYGON ((439586.516 4475753.323, 439594.830 4... | 1 | . 3 079602 | 153803 | Madrid-Arganzuela | POLYGON ((440345.316 4472954.760, 440386.546 4... | 1 | . 4 079605 | 145849 | Madrid-Chamartín | POLYGON ((441493.281 4478894.285, 441494.562 4... | 1 | . print (gdf[gdf.restricted==&#39;1&#39;].pob_pad19.sum(), &#39;people restricted in 10 municipalities,&#39;, int(.5+100*gdf[gdf.restricted==&#39;1&#39;].pob_pad19.sum()/gdf.pob_pad19.sum()),&#39;% of the population of the region&#39;) . 4786948 people restricted in 10 municipalities, 72 % of the population of the region . def col_func(fecha): return fecha[3]+fecha[4]+fecha[2]+fecha[0]+fecha[1] . . plotnine.options.figure_size = (14, 8) ggplot(munis_df[munis_df.fecha_informe&gt;&#39;08/24&#39;], aes(x=&#39;tasa_bin&#39;, fill=&#39;restricted&#39;)) + geom_histogram(binwidth=1, alpha=0.6, position=&#39;stack&#39;) + facet_wrap(&#39;fecha_informe&#39;, labeller=labeller(cols=col_func)) + theme_minimal() + labs(title=&quot;Evolución de municipios/distritos con restricciones en las últimas 6 semanas&quot;, x=&#39;Tasa incidencia acumulada ultimos 14 días&#39;, y=&quot;Número de municipios / distritos&quot;) . /usr/local/lib/python3.6/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead if pdtypes.is_categorical(arr): . &lt;ggplot: (-9223363273197295202)&gt; . week_df=munis_df[munis_df.fecha_informe==munis_df.fecha_informe.unique().max()][[&#39;municipio_distrito&#39;,&#39;tasa&#39;,&#39;casos&#39;,&#39;tasa_bin&#39;,&#39;restricted&#39;]] gdf=gdf.merge(week_df,left_index=True, right_index=True) print(&#39;Restricted area in 10 municipalities&#39;) week_df[week_df.restricted==&#39;1&#39;].sort_values(&#39;tasa&#39;, ascending=False)[[&#39;municipio_distrito&#39;, &#39;tasa&#39;, &#39;casos&#39;]] . Restricted area in 10 municipalities . municipio_distrito tasa casos . 12 Madrid-Puente de Vallecas | 1185.83 | 2785 | . 59 Fuenlabrada | 1165.72 | 2258 | . 86 Parla | 1155.82 | 1504 | . 11 Madrid-Usera | 1049.08 | 1466 | . 18 Madrid-Villaverde | 1005.73 | 1498 | . 177 Alcobendas | 979.15 | 1146 | . 10 Madrid-Carabanchel | 960.49 | 2431 | . 19 Madrid-Villa de Vallecas | 866.22 | 956 | . 16 Madrid-Ciudad Lineal | 814.21 | 1761 | . 20 Madrid-Vicálvaro | 808.70 | 583 | . 13 Madrid-San Blas - Canillejas | 808.13 | 1278 | . 184 Torrejón de Ardoz | 795.43 | 1045 | . 195 Getafe | 773.28 | 1418 | . 9 Madrid-Latina | 767.36 | 1828 | . 1 Madrid-Salamanca | 766.58 | 1120 | . 22 Alcorcón | 753.60 | 1285 | . 2 Madrid-Centro | 753.44 | 1016 | . 5 Madrid-Tetuán | 727.74 | 1150 | . 80 Leganés | 724.74 | 1376 | . 15 Madrid-Moratalaz | 707.41 | 669 | . 3 Madrid-Arganzuela | 683.34 | 1051 | . 79 Móstoles | 629.11 | 1316 | . 4 Madrid-Chamartín | 627.36 | 915 | . 0 Madrid-Retiro | 624.39 | 745 | . 14 Madrid-Barajas | 602.72 | 295 | . 8 Madrid-Moncloa-Aravaca | 584.50 | 698 | . 7 Madrid-Fuencarral-El Pardo | 561.52 | 1381 | . 6 Madrid-Chamberí | 558.19 | 778 | . 178 Alcalá de Henares | 524.92 | 1027 | . 17 Madrid-Hortaleza | 494.72 | 931 | . gdf[&#39;unrestricted&#39;]=&#39;0&#39; gdf.loc[week_df[20:][(week_df[20:].tasa&gt;1000) &amp; (week_df[20:].restricted==&#39;0&#39;)].municipio_distrito.index, &#39;unrestricted&#39;]=&#39;1&#39; print((100_000*munis_df.loc[:20].casos.sum()/gdf.loc[:20].pob_pad19.sum()+.5).astype(&#39;int&#39;),&#39;rate for Madrid capital&#39;) . 776 rate for Madrid capital . print(len(week_df[20:][(week_df[20:].tasa&gt;1000) &amp; (week_df[20:].restricted==&#39;0&#39;)]),&#39;other municipalities with a rate over 1000&#39;) week_df[20:][(week_df[20:].tasa&gt;1000) &amp; (week_df[20:].restricted==&#39;0&#39;)].sort_values(&#39;tasa&#39;, ascending=False)[[&#39;municipio_distrito&#39;, &#39;tasa&#39;, &#39;casos&#39;]] . 19 other municipalities with a rate over 1000 . municipio_distrito tasa casos . 81 Braojos | 2439.02 | 5 | . 165 Canencia | 1789.71 | 8 | . 148 Rozas de Puerto Real | 1698.11 | 9 | . 29 Puebla de la Sierra | 1538.46 | 0 | . 152 Villa del Prado | 1518.40 | 99 | . 87 Fuentidueña de Tajo | 1509.99 | 31 | . 103 El Berrueco | 1447.37 | 11 | . 115 Humanes de Madrid | 1423.29 | 281 | . 172 Navalagamella | 1341.00 | 35 | . 194 Cervera de Buitrago | 1333.33 | 0 | . 157 Torrelaguna | 1323.53 | 63 | . 197 Villaconejos | 1180.64 | 40 | . 132 Casarrubuelos | 1164.64 | 44 | . 82 Cubas de la Sagra | 1138.31 | 73 | . 192 Orusco de Tajuña | 1125.40 | 14 | . 159 El Atazar | 1123.60 | 0 | . 26 Moraleja de Enmedio | 1070.87 | 55 | . 105 Villar del Olmo | 1044.26 | 21 | . 100 Cobeña | 1036.62 | 77 | . print(&#39;total population of these municipalities is only&#39;,gdf.iloc[week_df[20:][(week_df[20:].tasa&gt;1000) &amp; (week_df[20:].restricted==&#39;0&#39;)].municipio_distrito.index].pob_pad19.sum()) . total population of these municipalities is only 67330 . gdf.iloc[week_df[20:][(week_df[20:].tasa&gt;1000) &amp; (week_df[20:].restricted==&#39;0&#39;)].municipio_distrito.index].sort_values(&#39;pob_pad19&#39;, ascending=False)[[&#39;municipio_&#39;,&#39;pob_pad19&#39;]] . municipio_ pob_pad19 . 115 Humanes de Madrid | 19743 | . 100 Cobeña | 7428 | . 152 Villa del Prado | 6520 | . 82 Cubas de la Sagra | 6413 | . 26 Moraleja de Enmedio | 5136 | . 157 Torrelaguna | 4760 | . 132 Casarrubuelos | 3778 | . 197 Villaconejos | 3388 | . 172 Navalagamella | 2610 | . 87 Fuentidueña de Tajo | 2053 | . 105 Villar del Olmo | 2011 | . 192 Orusco de Tajuña | 1244 | . 103 El Berrueco | 760 | . 148 Rozas de Puerto Real | 530 | . 165 Canencia | 447 | . 81 Braojos | 205 | . 194 Cervera de Buitrago | 150 | . 159 El Atazar | 89 | . 29 Puebla de la Sierra | 65 | . Basic Health Areas . zones_df=pd.read_csv(&#39;./fastpages/covid19_tia_zonas_basicas_salud_s.csv&#39;, delimiter=&#39;;&#39;, encoding=&#39;latin&#39;) # source: http://datos.comunidad.madrid/catalogo/dataset/covid19_tia_zonas_basicas_salud for col in [&#39;tasa_incidencia_acumulada_activos_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_total&#39;]: zones_df[col] = pd.to_numeric(zones_df[col].apply(lambda x: re.sub(&#39;,&#39;, &#39;.&#39;, x))) zones_df.rename(columns={&#39;zona_basica_salud&#39;:&#39;zona_basic&#39;,&#39;tasa_incidencia_acumulada_ultimos_14dias&#39;:&#39;tasa&#39;, &#39;casos_confirmados_ultimos_14dias&#39;:&#39;casos&#39;}, inplace=True) zones_df.fecha_informe=zones_df.fecha_informe.apply(lambda x: x[5:10]) print(len(zones_df[(zones_df.tasa&gt;1000) &amp; (zones_df.fecha_informe==&#39;09/29&#39;)]),&#39;basic health areas with a rate of over 1 000 per 100 000 population in the last 14 days&#39;) zones_df[(zones_df.tasa&gt;1000) &amp; (zones_df.fecha_informe==&#39;09/29&#39;)].sort_values(&#39;tasa&#39;, ascending=False)[[&#39;zona_basic&#39;,&#39;tasa&#39;]] . 49 basic health areas with a rate of over 1 000 per 100 000 population in the last 14 days . zona_basic tasa . 10 Alicante | 1656.24 | . 62 Cuzco | 1640.59 | . 215 Puerta Bonita | 1525.38 | . 210 Pozo de Tío Raimundo | 1486.94 | . 202 Peña Prieta | 1483.68 | . 85 Entrevías | 1447.75 | . 232 San Blas | 1386.96 | . 233 San Cristóbal | 1360.38 | . 111 Humanes de Madrid | 1350.54 | . 234 San Diego | 1340.20 | . 71 Doctor Trueta | 1339.11 | . 274 Villa del Prado | 1335.76 | . 7 Alcobendas - Chopera | 1335.12 | . 231 San Andrés | 1326.57 | . 132 Las Calesas | 1290.74 | . 206 Pintores | 1283.70 | . 161 Martínez de la Riva | 1281.28 | . 171 Miraflores | 1277.18 | . 285 Zofío | 1274.35 | . 115 Isabel II | 1271.29 | . 219 Rafael Alberti | 1270.91 | . 273 Villa Vallecas | 1267.03 | . 135 Las Margaritas | 1244.43 | . 224 Reyes Católicos | 1202.16 | . 193 Panaderas | 1151.16 | . 11 Almendrales | 1148.20 | . 169 Miguel Servet | 1146.48 | . 121 La Elipa | 1137.61 | . 59 Comillas | 1128.86 | . 250 Sierra de Guadarrama | 1123.82 | . 78 El Naranjo | 1118.60 | . 150 Los Rosales | 1116.31 | . 237 San Isidro | 1114.40 | . 255 Torrelaguna | 1107.82 | . 51 Ciudad San Pablo | 1101.67 | . 15 Ángela Uriarte | 1084.83 | . 268 Valleaguado | 1081.95 | . 134 Las Fronteras | 1081.33 | . 92 Francia | 1078.18 | . 67 Doctor Cirajas | 1077.14 | . 38 Campo de la Paloma | 1073.69 | . 40 Canillejas | 1071.17 | . 185 Numancia | 1066.68 | . 97 Gandhi | 1065.68 | . 284 Vista Alegre | 1060.58 | . 271 Vicálvaro - Artilleros | 1030.43 | . 6 Alcalá de Guadaira | 1028.15 | . 16 Antonio Leyva | 1023.47 | . 162 María Curie | 1016.51 | . zones_df.tasa.fillna(0, inplace=True) # allocates rates to bins cut_labels=[&#39;&lt;200&#39;,&#39;200-400&#39;,&#39;400-600&#39;,&#39;600-800&#39;,&#39;800-1000&#39;,&#39;&gt;1000&#39;] cut_bins = [-1., 200., 400., 600., 800., 1000., max(zones_df.tasa)] zones_df[&#39;tasa_bin&#39;] = pd.cut(zones_df.tasa, bins=cut_bins, labels=cut_labels) week_df=zones_df[zones_df.fecha_informe==zones_df.fecha_informe.unique().max()][[&#39;zona_basic&#39;,&#39;tasa&#39;,&#39;casos&#39;,&#39;tasa_bin&#39;]] df=(geopandas.read_file(&#39;./maps/zonas_basicas_salud/zonas_basicas_salud.shp&#39;)).merge(week_df) # basic health areas with restrictions df[&#39;restricted&#39;]=&#39;0&#39; for zone in [&#39;Humanes de Madrid&#39;,&#39;Reyes Católicos&#39;,&#39;Villa del Prado&#39;]: df.loc[df.zona_basic==zone, &#39;restricted&#39;]=&#39;1&#39; df[&#39;&gt;1000&#39;]=df.tasa.apply(lambda x: 1 if x&gt;1000 else 0) . Maps of municipalities and basic health areas . fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(18,9)) gdf.plot(ax=ax1, column=gdf.tasa_bin, cmap=&#39;Reds&#39;, legend=True) gdf.plot(ax=ax1, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax1.set_title(&#39;Rate of accumulated incidence n by municipality&#39;) ax1.axis(&#39;off&#39;) gdf.plot(ax=ax2, column=gdf.restricted_x, cmap=&#39;Reds&#39;, legend=False) gdf.plot(ax=ax2, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax2.set_title(&#39;Restricted municipalities npopulation &gt;100 000 nrate of over 500 per 100 000&#39;) ax2.axis(&#39;off&#39;); gdf.plot(ax=ax3, column=gdf.unrestricted, cmap=&#39;Reds&#39;, legend=False) gdf.plot(ax=ax3, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax3.set_title(&#39;Municipalities with a rate &gt; 1000 npopulation &lt; 100 000&#39;) ax3.axis(&#39;off&#39;); . . fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(18,9)) df.plot(ax=ax1, column=df.tasa_bin, cmap=&#39;Reds&#39;, legend=True) df.plot(ax=ax1, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax1.set_title(&#39;Rate of accumulated incidence n by basic health area&#39;) ax1.axis(&#39;off&#39;) df.plot(ax=ax2, column=df[&#39;&gt;1000&#39;], cmap=&#39;Reds&#39;, alpha=1, legend=False) df.plot(ax=ax2, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax2.set_title(&#39;Basic health areas with a rate &gt; 1000&#39;) ax2.axis(&#39;off&#39;); df.plot(ax=ax3, column=df.restricted, cmap=&#39;Reds&#39;, alpha=1, legend=False) gdf[gdf.restricted_x==&#39;1&#39;].plot(ax=ax3, color=&#39;red&#39;) df.plot(ax=ax3, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax3.set_title(&#39;Restricted basic health areas n(rate &gt; 1 000 per 100 000) nand restricted 10 large municipalities&#39;) ax3.axis(&#39;off&#39;); . . Closing Remarks . Colour coded maps showing the infection rates, whether for municipalities or basic health areas give a misleading impression because the population of the Madrid region is concentrated in the capital and the surrounding densely populated municipalities. Covid19 affects people but people are not uniformly distributed across the region. . Basic health areas are more heterogeneous, being based on population and access to local health centres, than municipalities, which vary enormously in population. .",
            "url": "https://alisondavey.github.io/fastpages/madrid/covid19/municipios/2020/10/05/municipalities.html",
            "relUrl": "/madrid/covid19/municipios/2020/10/05/municipalities.html",
            "date": " • Oct 5, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Rates of Covid19 in Madrid",
            "content": "!pip install geopandas import pandas as pd import numpy as np import re import geopandas import plotnine from plotnine import * import matplotlib.pyplot as plt import matplotlib.tri as tri from mpl_toolkits.axes_grid1 import make_axes_locatable from sklearn.metrics import confusion_matrix %matplotlib inline . . Covid19 Weekly Data from the &#39;Comunidad de Madrid&#39; . https://datos.comunidad.madrid/catalogo/dataset/covid19_tia_zonas_basicas_salud . Covid 19-TIA Zonas B&#225;sicas de Salud (CSV) . On a Tuesday morning, weekly data are provided for the 286 basic health areas: . confirmed cases and rate of accumulated incidence for basic health areas | the source of data is the Madrid region&#39;s network of epidemiological vigilence | the data are continually updated; you should always show the date when the data were accessed | the polygon data includes the population figures from the region&#39;s statistical institute from the population register of 1 January 2019. | . &quot;Información epidemiológica Covid-19: Casos confirmados y tasa de incidencia acumulada (TIA) por Zonas Básicas de Salud (Decreto 52/2010, de 29 de julio, BOCM 9 de agosto de 2010). Informe diario o semanal con datos de casos confirmados, casos confirmados con infección activa y tasas de incidencia acumulada de los últimos 14 días y desde el inicio de la epidemia (25 de febrero de 2020). La fuente de los datos es la Red de Vigilancia Epidemiológica de la Comunidad de Madrid. Cuando se utilicen los datos se debe indicar en qué fecha se ha accedido a los mismos, dada su actualización continua. Hasta el 1 de julio de 2020 los registros de datos correspondientes a cada fecha de informe se han añadido diariamente. A partir del 2 de julio de 2020 la actualización pasa a ser semanal. A fecha 1 de junio, se ha procedido a actualizar el conjunto de datos de Zonas Básicas de Salud, con los datos actualizados de geometrías proporcionados por el Instituto de Estadística de la Comunidad de Madrid. Las nuevas geometrías incluyen los datos poblacionales actualizados por el Instituto de Estadística de la Comunidad de Madrid, relativos al Padrón Continuo a 1 de enero de 2019.&quot; . Here we will read the CSV data dated 29 September 2020 and explore: . zones_df=pd.read_csv(&#39;covid19_tia_zonas_basicas_salud_s.csv&#39;, delimiter=&#39;;&#39;, encoding=&#39;latin&#39;) . print (&#39;Columns:&#39;) [print(col) for col in list(zones_df.columns)] print() print(&#39;Shape: &#39;,zones_df.shape) print() print(&#39;Dates: &#39;,list(zones_df.fecha_informe.unique())) . . Columns: zona_basica_salud fecha_informe casos_confirmados_activos_ultimos_14dias tasa_incidencia_acumulada_activos_ultimos_14dias casos_confirmados_ultimos_14dias tasa_incidencia_acumulada_ultimos_14dias casos_confirmados_totales tasa_incidencia_acumulada_total codigo_geometria Shape: (5434, 9) Dates: [&#39;2020/09/29 11:15:00&#39;, &#39;2020/09/22 09:42:00&#39;, &#39;2020/09/15 10:23:00&#39;, &#39;2020/09/08 11:03:00&#39;, &#39;2020/09/01 09:33:00&#39;, &#39;2020/08/25 09:33:00&#39;, &#39;2020/08/18 09:32:00&#39;, &#39;2020/08/11 09:31:00&#39;, &#39;2020/08/04 09:58:00&#39;, &#39;2020/07/28 09:34:00&#39;, &#39;2020/07/21 09:23:00&#39;, &#39;2020/07/14 09:23:00&#39;, &#39;2020/07/07 09:32:00&#39;, &#39;2020/06/30 07:00:00&#39;, &#39;2020/06/23 07:00:00&#39;, &#39;2020/06/16 07:00:00&#39;, &#39;2020/06/09 07:00:00&#39;, &#39;2020/06/02 07:00:00&#39;, &#39;2020/05/26 07:00:00&#39;] . Tidy-up the dataframe by . replacing decimal , with decimal . | shortening key column names | dropping time from the date column | . for col in [&#39;tasa_incidencia_acumulada_activos_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_ultimos_14dias&#39;, &#39;tasa_incidencia_acumulada_total&#39;]: zones_df[col] = pd.to_numeric(zones_df[col].apply(lambda x: re.sub(&#39;,&#39;, &#39;.&#39;, x))) zones_df.rename(columns={&#39;zona_basica_salud&#39;:&#39;zona_basic&#39;,&#39;tasa_incidencia_acumulada_ultimos_14dias&#39;:&#39;tasa&#39;, &#39;casos_confirmados_ultimos_14dias&#39;:&#39;casos&#39;}, inplace=True) zones_df.fecha_informe=zones_df.fecha_informe.apply(lambda x: x[5:10]) . Data for the centre of Madrid (where the main office of the regional authority are located). . zones_df[zones_df.zona_basic==&#39;Cortes&#39;].T . 60 346 632 918 1204 1490 1776 2062 2348 2651 2920 3206 3492 3778 4064 4350 4636 4922 5208 . zona_basic Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | Cortes | . fecha_informe 09/29 | 09/22 | 09/15 | 09/08 | 09/01 | 08/25 | 08/18 | 08/11 | 08/04 | 07/28 | 07/21 | 07/14 | 07/07 | 06/30 | 06/23 | 06/16 | 06/09 | 06/02 | 05/26 | . casos_confirmados_activos_ultimos_14dias 49 | 67 | 18 | 17 | 14 | 17 | 33 | 15 | 19 | 10 | NaN | NaN | NaN | NaN | NaN | 7 | NaN | NaN | NaN | . tasa_incidencia_acumulada_activos_ultimos_14dias 185.94 | 254.25 | 68.31 | 64.51 | 53.13 | 64.51 | 125.23 | 56.92 | 72.1 | 37.95 | 18.97 | 15.18 | 3.79 | 3.79 | 18.97 | 26.56 | 15.18 | 3.79 | 3.79 | . casos 203 | 188 | 188 | 169 | 147 | 89 | 64 | 49 | 27 | 19 | 7 | NaN | NaN | NaN | 8 | 10 | 10 | 7 | NaN | . tasa 770.34 | 713.42 | 713.42 | 641.32 | 557.83 | 337.74 | 242.87 | 185.94 | 102.46 | 72.1 | 26.56 | 18.97 | 7.59 | 11.38 | 30.36 | 37.95 | 37.95 | 26.56 | 15.18 | . casos_confirmados_totales 939 | 820 | 713 | 613 | 522 | 429 | 365 | 332 | 293 | 281 | 264 | 261 | 251 | 246 | 245 | 242 | 236 | 231 | 226 | . tasa_incidencia_acumulada_total 3563.3 | 3111.72 | 2705.68 | 2326.2 | 1980.87 | 1627.96 | 1385.09 | 1259.87 | 1111.87 | 1066.33 | 1001.82 | 990.44 | 952.49 | 933.52 | 929.72 | 918.34 | 895.57 | 876.59 | 857.62 | . codigo_geometria 061 | 061 | 061 | 061 | 061 | 061 | 061 | 061 | 061 | | 061 | 061 | 061 | 061 | 061 | 061 | 061 | 061 | 061 | . fig, ax = plt.subplots(1,1,figsize=(10,5)) plt.plot(zones_df[zones_df.zona_basic==&#39;Cortes&#39;].fecha_informe[::-1], zones_df[zones_df.zona_basic==&#39;Cortes&#39;].casos[::-1]) plt.title(&#39;Cases confirmed in the last 14 days - Cortes&#39;); . fig, ax = plt.subplots(1,1,figsize=(10,5)) plt.plot(zones_df[zones_df.zona_basic==&#39;Cortes&#39;].fecha_informe[::-1], zones_df[zones_df.zona_basic==&#39;Cortes&#39;].tasa[::-1]) plt.ylim(0,1000) plt.title(&#39;Rate of accumulated incidence for 100 000 people in the last 14 days - Cortes&#39;); . print(len(zones_df.zona_basic.unique())) print(zones_df.zona_basic.unique()[:10]) . 286 [&#39;Abrantes&#39; &#39;Acacias&#39; &#39;Adelfas&#39; &#39;Alameda&#39; &#39;Alameda de Osuna&#39; &#39;Alcalde Bartolomé González&#39; &#39;Alcalá de Guadaira&#39; &#39;Alcobendas - Chopera&#39; &#39;Alcocer&#39; &#39;Algete&#39;] . Allocate to bins based on rate . zones_df.tasa.fillna(0, inplace=True) cut_labels=[&#39;&lt;200&#39;,&#39;200-400&#39;,&#39;400-600&#39;,&#39;600-800&#39;,&#39;800-1000&#39;,&#39;&gt;1000&#39;] cut_bins = [-1., 200., 400., 600., 800., 1000., max(zones_df.tasa)] zones_df[&#39;tasa_bin&#39;] = pd.cut(zones_df.tasa, bins=cut_bins, labels=cut_labels) zones_df.tasa_bin.value_counts() . &lt;200 3667 200-400 654 400-600 475 600-800 301 &gt;1000 175 800-1000 162 Name: tasa_bin, dtype: int64 . Helper function to check for errors in the presentation of the names, e.g. spaces, &#39;de&#39;,... . def check_zones(zonas_restricted): lst=[] for zona_basic in zones_df.zona_basic[:286]: if zona_basic in zonas_restricted: lst.append(zona_basic) print(len(lst), set(zonas_restricted)-set(lst)) . . Identify the initial 37 areas restricted from 21 September 2020: . zonas_restricted_1=[&quot;Puerta Bonita&quot;,&quot;Vista Alegre&quot;,&quot;Guayaba&quot;, &quot;Almendrales&quot;, &quot;Las Calesas&quot;, &quot;Zofío&quot;, &quot;Orcasur&quot;, &quot;San Fermín&quot;, &quot;San Andrés&quot;, &quot;San Cristóbal&quot;, &quot;El Espinillo&quot;, &quot;Los Rosales&quot;, &quot;Villa Vallecas&quot;, &quot;Entrevías&quot;, &quot;Martínez de la Riva&quot;, &quot;San Diego&quot;, &quot;Numancia&quot;, &quot;Peña Prieta&quot;, &quot;Pozo de Tío Raimundo&quot;, &quot;Ángela Uriarte&quot;, &quot;Alcalá de Guadaira&quot;, &quot;Federica Montseny&quot;, &quot;Doctor Cirajas&quot;, &quot;Gandhi&quot;, &quot;Daroca&quot;, &quot;La Elipa&quot;, &quot;Alicante&quot;, &quot;Cuzco&quot;, &quot;Francia&quot;, &quot;Humanes de Madrid&quot;, &quot;San Blas&quot;, &quot;Isabel II&quot;, &quot;Las Margaritas&quot;, &quot;Sánchez Morate&quot;, &quot;Reyes Católicos&quot;, &quot;Alcobendas - Chopera&quot;, &quot;Miraflores&quot;] check_zones(zonas_restricted_1) . 37 set() . Identify the additional 8 areas restricted from 28 September 2020: . zonas_restricted_2=[&quot;Panaderas&quot;, &quot;Doctor Trueta&quot;, &quot;Miguel Servet&quot;, &quot;Campo de la Paloma&quot;, &quot;Rafael Alberti&quot;, &quot;García Noblejas&quot;, &quot;Vicálvaro - Artilleros&quot;,&quot;Orcasitas&quot;] check_zones(zonas_restricted_2) . 8 set() . Label zones with restricted group . zones_df[&#39;restricted&#39;]=&#39;0&#39; for i in range(len(zonas_restricted_1)): zones_df.loc[zones_df.zona_basic==zonas_restricted_1[i], &#39;restricted&#39;]=&#39;1&#39; for i in range(len(zonas_restricted_2)): zones_df.loc[zones_df.zona_basic==zonas_restricted_2[i], &#39;restricted&#39;]=&#39;2&#39; zones_df.restricted.value_counts()/len(zones_df.fecha_informe.unique()) . 0 241.0 1 37.0 2 8.0 Name: restricted, dtype: float64 . Helper function to reorder the presentation of the dates . def col_func(fecha): return fecha[3]+fecha[4]+fecha[2]+fecha[0]+fecha[1] . . Histograms of number of zones in each category in the last 6 weeks . plotnine.options.figure_size = (14, 8) ggplot(zones_df[zones_df.fecha_informe&gt;&#39;08/24&#39;], aes(x=&#39;tasa_bin&#39;, fill=&#39;restricted&#39;)) + geom_histogram(binwidth=1, alpha=0.6, position=&#39;stack&#39;) + facet_wrap(&#39;fecha_informe&#39;, labeller=labeller(cols=col_func)) + theme_minimal() + labs(title=&quot;Zonas básicas de salud&quot;, x=&#39;Tasa incidencia acumulada ultimos 14 días&#39;, y=&quot;Número de zonas&quot;) + scale_fill_brewer(palette = &#39;Reds&#39;) . /usr/local/lib/python3.6/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead if pdtypes.is_categorical(arr): . &lt;ggplot: (8761571081273)&gt; . Maps for the most recent week . week_df=zones_df[zones_df.fecha_informe==zones_df.fecha_informe.unique().max()][[&#39;zona_basic&#39;,&#39;tasa&#39;,&#39;casos&#39;,&#39;tasa_bin&#39;,&#39;restricted&#39;]] df=(geopandas.read_file(&#39;./maps/zonas_basicas_salud.shp&#39;)).merge(week_df) df[&#39;geometry_pt&#39;]=df.geometry.centroid df.head().T . 0 1 2 3 4 . codigo_geo 001 | 002 | 003 | 004 | 005 | . pob_pad19 30748 | 19432 | 29168 | 21274 | 29001 | . zona_basic Abrantes | Acacias | Adelfas | Alameda | Alameda de Osuna | . geometry POLYGON ((439068.7580000004 4470731.660800001,... | POLYGON ((439924.9298999999 4472798.281400001,... | POLYGON ((443455.7175000003 4472836.7236, 4434... | POLYGON ((440659.7537000002 4473778.4014, 4406... | POLYGON ((452408.1383999996 4484644.699999999,... | . tasa 913.88 | 504.32 | 551.97 | 766.19 | 610.32 | . casos 281 | 98 | 161 | 163 | 177 | . tasa_bin 800-1000 | 400-600 | 400-600 | 600-800 | 600-800 | . restricted 0 | 0 | 0 | 0 | 0 | . geometry_pt POINT (438360.9828817752 4470073.107306919) | POINT (439858.3553289876 4472447.600519221) | POINT (442903.0377880885 4472532.970746173) | POINT (440836.3215957115 4473539.390589811) | POINT (451700.7212964218 4480650.657189403) | . Maps of rate of accumulated instance and restricted zones . fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(12,6)) df.plot(ax=ax1, column=df.tasa_bin, cmap=&#39;Reds&#39;, legend=True) df.plot(ax=ax1, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax1.set_title(&#39;Rate of accumulated incidence&#39;) ax1.axis(&#39;off&#39;) df.plot(ax=ax2, column=df.restricted, cmap=&#39;Reds&#39;, legend=True) df.plot(ax=ax2, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax2.set_title(&#39;Restricted zones&#39;) ax2.axis(&#39;off&#39;); . df.tasa_bin.value_counts() . 600-800 89 400-600 78 &gt;1000 49 800-1000 49 200-400 21 &lt;200 0 Name: tasa_bin, dtype: int64 . df.restricted.value_counts() . 0 241 1 37 2 8 Name: restricted, dtype: int64 . Treating the rate as a surface and plotting contours . Linear interpolation of the rate at the centroid of each zone . def getXY(pt): return (pt.x, pt.y) . def data_for_week(fecha): week_df=zones_df[zones_df.fecha_informe==fecha][[&#39;zona_basic&#39;,&#39;tasa&#39;,&#39;casos&#39;,&#39;tasa_bin&#39;,&#39;restricted&#39;]] df=geopandas.read_file(&#39;./maps/zonas_basicas_salud.shp&#39;).merge(week_df) x, y = [list(t) for t in zip(*map(getXY, df.geometry.centroid))] z = df.tasa return x,y,z . def multi_plot(i): fecha=weeks[i] x,y,z = data_for_week(fecha) fig, ax = plt.subplots(1,1,figsize=(10,8)) ax.set(xlim=(360000, 500000), ylim=(4420000, 4550000)) cntr = ax.tricontourf(x, y, z, [0,200,400,800,1000,2000], cmap=&quot;Reds&quot;) # plot contour fill df.plot(color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1, ax=ax) divider = make_axes_locatable(ax) cax = divider.append_axes(&quot;right&quot;, size=&quot;5%&quot;, pad=0.0) fig.colorbar(cntr, drawedges=False, cax=cax) ax.set_title(f&#39;Tasa incidencia acumulada en los últimos 14 días n fecha {fecha[3]+fecha[4]+fecha[2]+fecha[0]+fecha[1]}, maximum {str(int(max(z)))}/100000 habitantes&#39;) ax.axis(&#39;off&#39;) . weeks = zones_df.fecha_informe.unique()[:8][::-1] for i in range(len(weeks)): multi_plot(i) . Plots for 4 weeks . def plot_4_weeks(plot_weeks): fig, axs = plt.subplots(1, 4, figsize=(16, 4)) for i in range(4): fecha=plot_weeks[i] x,y,z = data_for_week(plot_weeks[i]) df.plot(color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1, ax=axs[i]) axs[i].set_title(f&#39; nfecha {fecha[3]+fecha[4]+fecha[2]+fecha[0]+fecha[1]} nmax. {str(int(max(z)))}/100000 hab.&#39;, fontsize=8) axs[i].axis(&#39;off&#39;) cntr=axs[i].tricontourf(x,y,z,[0,200,400,800,1000,2000], cmap=&quot;Reds&quot;) divider = make_axes_locatable(axs[-1]) cax = divider.append_axes(&quot;right&quot;, size=&quot;3%&quot;, pad=0.0) fig.colorbar(cntr, drawedges=False, cax=cax) fig.suptitle(&#39;Tasa incidencia acumulada en los últimos 14 días&#39;, fontsize=12, va=&#39;baseline&#39;) plt.savefig(&#39;four_weeks.png&#39;, bbox_inches=&#39;tight&#39;); . . plot_4_weeks(weeks[:4]) . plot_4_weeks(weeks[4:]) . Confusion matrix for rate &gt; 1000 and restrictions . week_df=zones_df[zones_df.fecha_informe==zones_df.fecha_informe.max()][[&#39;zona_basic&#39;,&#39;tasa&#39;,&#39;casos&#39;,&#39;tasa_bin&#39;,&#39;restricted&#39;]] df=(geopandas.read_file(&#39;./maps/zonas_basicas_salud.shp&#39;)).merge(week_df) print(confusion_matrix((df.restricted != &#39;0&#39;)*1, (df.tasa&gt;1000)*1)) . [[228 13] [ 9 36]] . 228 zones with rate less than 1000 and no restrictions. | 36 zones with rate over 1000 and restrictions. | . 13 zones with rate over 1000 but no restrictions . df[(df.restricted == &#39;0&#39;) &amp; (df.tasa&gt;1000)][[&#39;zona_basic&#39;,&#39;tasa&#39;]].sort_values(&#39;tasa&#39;, ascending=False) . zona_basic tasa . 274 Villa del Prado | 1335.76 | . 206 Pintores | 1283.70 | . 59 Comillas | 1128.86 | . 250 Sierra de Guadarrama | 1123.82 | . 78 El Naranjo | 1118.60 | . 237 San Isidro | 1114.40 | . 255 Torrelaguna | 1107.82 | . 51 Ciudad San Pablo | 1101.67 | . 268 Valleaguado | 1081.95 | . 134 Las Fronteras | 1081.33 | . 40 Canillejas | 1071.17 | . 16 Antonio Leyva | 1023.47 | . 162 María Curie | 1016.51 | . 9 zones with rate under 1000 but restricted . df[(df.restricted != &#39;0&#39;) &amp; (df.tasa&lt;1000)][[&#39;zona_basic&#39;,&#39;tasa&#39;]].sort_values(&#39;tasa&#39;) . zona_basic tasa . 235 San Fermín | 738.58 | . 188 Orcasitas | 788.33 | . 74 El Espinillo | 835.19 | . 189 Orcasur | 883.03 | . 98 García Noblejas | 889.98 | . 108 Guayaba | 898.50 | . 90 Federica Montseny | 900.03 | . 254 Sánchez Morate | 934.83 | . 64 Daroca | 950.19 | . Weak relationship between population density and rate . df[&#39;area_sq_km&#39;] = df.geometry.area/1_000_000 df[&#39;pob_densidad_sq_km&#39;] = df.pob_pad19/df.area_sq_km df[[&#39;tasa&#39;,&#39;pob_densidad_sq_km&#39;]].corr() . tasa pob_densidad_sq_km . tasa 1.000000 | 0.380547 | . pob_densidad_sq_km 0.380547 | 1.000000 | . ggplot(df, aes(x=&#39;pob_densidad_sq_km&#39;,y=&#39;tasa&#39;,color=&#39;restricted&#39;)) + geom_point() + geom_smooth(aes(x=&#39;pob_densidad_sq_km&#39;,y=&#39;tasa&#39;), color=&#39;black&#39;,method = &quot;lm&quot;) . /usr/local/lib/python3.6/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead if pdtypes.is_categorical(arr): . &lt;ggplot: (8761570866352)&gt; . Comparison of individual zones to the best and worst . df_week=zones_df[zones_df.fecha_informe==zones_df.fecha_informe.max()] most = df_week[df_week.tasa==df_week.tasa.max()].zona_basic.to_list()[0] least = df_week[df_week.tasa==df_week.tasa.min()].zona_basic.to_list()[0] most, least . (&#39;Alicante&#39;, &#39;El Pardo&#39;) . zona = &#39;Cortes&#39; df_tmp = zones_df.pivot_table(values=&#39;tasa&#39;, index=&#39;fecha_informe&#39;, columns=&#39;zona_basic&#39;).reset_index() zbs = [most, zona, least] title= zbs[1] + &#39; compared to least (&#39; + zbs[2] + &#39;) and most (&#39; + zbs[0] + &#39;)&#39; ggplot(df_tmp, aes(x=&#39;fecha_informe&#39;,y=zbs[1],group=1)) + geom_point(colour=&#39;blue&#39;, alpha = 0.5) + geom_line(aes(y=zbs[1]), colour=&#39;blue&#39;) + geom_smooth(aes(y=zbs[0]), colour=&#39;red&#39; ) + geom_smooth(aes(y=zbs[2]), colour=&#39;green&#39;) + labs(title=title, x=&#39;Fecha informe&#39;, y=&quot;Tasa&quot;) + geom_text(data=df_tmp[df_tmp.fecha_informe==&#39;09/22&#39;],label=zbs[1], color=&#39;blue&#39;, hjust= &#39;right&#39;, vjust=&#39;bottom&#39;) + theme_minimal() . /usr/local/lib/python3.6/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead if pdtypes.is_categorical(arr): /usr/local/lib/python3.6/dist-packages/plotnine/stats/smoothers.py:168: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. &#34;for lowess smoothings.&#34;, PlotnineWarning) /usr/local/lib/python3.6/dist-packages/plotnine/stats/smoothers.py:168: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. &#34;for lowess smoothings.&#34;, PlotnineWarning) . &lt;ggplot: (8761578846640)&gt; .",
            "url": "https://alisondavey.github.io/fastpages/madrid/covid19/2020/09/29/Covid19Data.html",
            "relUrl": "/madrid/covid19/2020/09/29/Covid19Data.html",
            "date": " • Sep 29, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Basic Health Areas in Madrid",
            "content": "Since Monday, 21 September 2020 basic health zones have been used in Madrid to impose restrictions on the population in the fight against Covid19. This came as a surprise to the local population - they knew the name of their zone from the name of their health centre but had no idea about what area is served by the health centre. . In this series of block posts I would like to explore the public data on the second wave of Covid19 infections in Madrid using Jupyter notebooks that run on Google Colab and non-proprietory software. You too can access the data, run these notebooks and explore the data yourself. . If you are interested graphical analysis of the Covid19 crisis, I recommend the work of Kiko Llaneras and the team at El País. . This introductory notebook locates polygon data for these basic health zones and the detailed maps showing the area each zone serves. . Libraries to install and import: . !pip install geopandas !apt-get install poppler-utils !pip install pdf2image import geopandas import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable from pdf2image import convert_from_path, convert_from_bytes from pdf2image.exceptions import (PDFInfoNotInstalledError,PDFPageCountError,PDFSyntaxError) from PIL import Image . . Introduction to &#39;Zonas B&#225;sicas de Salud&#39; in the &#39;Comunidad de Madrid&#39; . The Comunidad de Madrid provides polygon data of the basic health zones as &#39;shape&#39; files. . These can be read using geopandas. . División territorial en zonas básicas de salud de la Comunidad de Madrid . https://datos.comunidad.madrid/catalogo/dataset/covid19_tia_zonas_basicas_salud/resource/f1837bd3-a835-4110-9bbf-fae06c99b56b . df=geopandas.read_file(&#39;./maps/zonas_basicas_salud.shp&#39;) df.head() . codigo_geo pob_pad19 zona_basic geometry . 0 001 | 30748 | Abrantes | POLYGON ((439068.758 4470731.661, 439076.433 4... | . 1 002 | 19432 | Acacias | POLYGON ((439924.930 4472798.281, 439928.742 4... | . 2 003 | 29168 | Adelfas | POLYGON ((443455.718 4472836.724, 443412.985 4... | . 3 004 | 21274 | Alameda | POLYGON ((440659.754 4473778.401, 440665.227 4... | . 4 005 | 29001 | Alameda de Osuna | POLYGON ((452408.138 4484644.700, 452415.138 4... | . df.info() . &lt;class &#39;geopandas.geodataframe.GeoDataFrame&#39;&gt; RangeIndex: 286 entries, 0 to 285 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 codigo_geo 286 non-null object 1 pob_pad19 286 non-null int64 2 zona_basic 286 non-null object 3 geometry 286 non-null geometry dtypes: geometry(1), int64(1), object(2) memory usage: 9.1+ KB . plt.hist(df.pob_pad19) plt.title(&#39;Distribution of population by areas&#39;) plt.ylabel(&#39;Number of areas&#39;) plt.box(False) plt.xlabel(&#39;Population&#39;); . df.describe() . pob_pad19 . count 286.000000 | . mean 23298.580420 | . std 9935.956169 | . min 2636.000000 | . 25% 16702.250000 | . 50% 21829.000000 | . 75% 28164.250000 | . max 63789.000000 | . df[df.pob_pad19==df.pob_pad19.min()] . codigo_geo pob_pad19 zona_basic geometry . 221 222 | 2636 | Rascafría | POLYGON ((436250.375 4539098.529, 436255.925 4... | . df[df.pob_pad19==df.pob_pad19.max()] . codigo_geo pob_pad19 zona_basic geometry . 158 159 | 63789 | Mar Báltico | POLYGON ((447970.223 4484559.958, 447972.423 4... | . There are 286 basic health zones, with an average population of around 23_000 people: the Rascafría area has only 2_636 people; the Mar Báltico area has 63_789 people. . df[&quot;area_sq_km&quot;] = df[&#39;geometry&#39;].area/1_000_000 df[&#39;pob_densidad_sq_km&#39;] = df.pob_pad19/df.area_sq_km df.head() . codigo_geo pob_pad19 zona_basic geometry area_sq_km pob_densidad_sq_km . 0 001 | 30748 | Abrantes | POLYGON ((439068.758 4470731.661, 439076.433 4... | 1.572304 | 19556.009302 | . 1 002 | 19432 | Acacias | POLYGON ((439924.930 4472798.281, 439928.742 4... | 0.774111 | 25102.351889 | . 2 003 | 29168 | Adelfas | POLYGON ((443455.718 4472836.724, 443412.985 4... | 0.852828 | 34201.514571 | . 3 004 | 21274 | Alameda | POLYGON ((440659.754 4473778.401, 440665.227 4... | 0.545204 | 39020.288131 | . 4 005 | 29001 | Alameda de Osuna | POLYGON ((452408.138 4484644.700, 452415.138 4... | 35.137286 | 825.362547 | . fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(12,6)) df.plot(ax=ax1, column=df.pob_pad19, cmap=&#39;Reds&#39;, legend=True) df.plot(ax=ax1, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax1.set_title(&#39;Total population n by basic health area&#39;) ax1.axis(&#39;off&#39;) df.plot(ax=ax2, column=df.pob_densidad_sq_km, cmap=&#39;Reds&#39;, legend=True) df.plot(ax=ax2, color=&#39;white&#39;, edgecolor=&#39;grey&#39;, alpha=0.1) ax2.set_title(&#39;Population density n by basic health area&#39;) ax2.axis(&#39;off&#39;); . df[df.pob_densidad_sq_km==df.pob_densidad_sq_km.min()] . codigo_geo pob_pad19 zona_basic geometry area_sq_km pob_densidad_sq_km . 221 222 | 2636 | Rascafría | POLYGON ((436250.375 4539098.529, 436255.925 4... | 258.120579 | 10.212281 | . df[df.pob_densidad_sq_km==df.pob_densidad_sq_km.max()] . codigo_geo pob_pad19 zona_basic geometry area_sq_km pob_densidad_sq_km . 160 161 | 17331 | Martín de Vargas | POLYGON ((440449.700 4472841.620, 440459.695 4... | 0.307034 | 56446.431071 | . print(f&#39;The Madrid region has an area of {int(df.area.sum()/1000000)} sq km, a population of {df.pob_pad19.sum()} and a population density of {int(1000000*df.pob_pad19.sum()/df.area.sum())} people per sq km.&#39;) . The Madrid region has an area of 8025 sq km, a population of 6663394 and a population density of 830 people per sq km. . Rascafría has a population density of only 10 people per sq km; Martín de Vargas has a population of 56_446 people per sq km. . Detailed maps are provided for each zone . List of zones: | . Mapas de Zonas Básicas de Salud del Área Única de la Comunidad de Madrid . https://www.madrid.org/iestadis/fijas/estructu/general/territorio/estructucartemzbs.htm . Individual maps: | . https://www.madrid.org/iestadis/fijas/estructu/general/territorio/descarga/zbs13_mar_baltico.pdf . (maps have been downloaded and stored in ./maps/...) . Conversion of maps from .pdf to .jpg: . convert_from_path(&#39;./maps/zbs13_mar_baltico.pdf&#39;)[0].resize((1414,1000)).save(&#39;./maps/159_mar_baltico.jpg&#39;) convert_from_path(&#39;./maps/zbs13_rascafria.pdf&#39;)[0].resize((1414,1000)).save(&#39;./maps/222_rascafria.jpg&#39;) convert_from_path(&#39;./maps/zbs13_martin_de_vargas.pdf&#39;)[0].resize((1414,1000)).save(&#39;./maps/161_martin_de_vargas.jpg&#39;) . . Image.open(&#39;./maps/222_rascafria.jpg&#39;) . Image.open(&#39;./maps/159_mar_baltico.jpg&#39;) . Image.open(&#39;./maps/161_martin_de_vargas.jpg&#39;) .",
            "url": "https://alisondavey.github.io/fastpages/madrid/covid19/2020/09/28/intro.html",
            "relUrl": "/madrid/covid19/2020/09/28/intro.html",
            "date": " • Sep 28, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Busy enjoying learning and practising data analytics, machine learning and deep learning with the wealth of open source resources available to all. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://alisondavey.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://alisondavey.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}